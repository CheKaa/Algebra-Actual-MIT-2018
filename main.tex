\documentclass[10pt,a4paper,oneside]{book}
\usepackage[a4paper,includeheadfoot,top=10mm,bottom=10mm,left=10mm,right=10mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath,amsthm,amssymb,amscd,array}
\usepackage{latexsym}
\usepackage{multicol} % нумерция в нескольких колонках
\usepackage{graphicx} 
%\usepackage{pdfsync}
\usepackage{pgf}
\usepackage{tikz}
\usepackage{tikz-cd}
\usetikzlibrary{arrows,backgrounds,patterns,matrix,shapes,fit,calc,shadows,plotmarks}
\usepackage{hyperref} % гиперссылки
\usepackage{cmap}       % Поддержка поиска русских слов в PDF (pdflatex)
\usepackage{indentfirst}% Красная строка в первом абзаце
\usepackage{misccorr}
\usepackage{arydshln} % штрихованые линии в массивах
\usepackage{mathtools} % выравнивание в матрицах
\usepackage{ccaption}
\usepackage{fancyhdr}
\usepackage{comment}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={blue!50!black},
    citecolor={blue!50!black},
    urlcolor={red!80!black}
}
% цвета для ссылок


\newtheorem{upr}{Упражнение}
\newtheorem{predl}{Предложение}
\newtheorem{komment}{Комментарий}
\newtheorem{conj}{Гипотеза}
\newtheorem{notation}{Обозначение}


\theoremstyle{definition}
\newtheorem{kit}{Кит}
\newtheorem*{rem}{Замечание}
\newtheorem{zad}{Задача}
\newtheorem*{defn}{{\color{yellow!20!red} Определение}}
\newtheorem*{fact}{Факт}
\newtheorem{thm}{{\color{red!40!black} Теорема}}
\newtheorem*{thmm}{Теорема}
\newtheorem{lem}{Лемма}
\newtheorem{cor}{Следствие}
\newtheorem{utvr}{Утверждение}




\renewcommand{\proofname}{Доказательство}
\renewcommand{\mod}{\,\operatorname{mod}\,}
\renewcommand{\Re}{\operatorname{Re}}
\newcommand{\mf}[1]{\mathfrak{#1}}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\tbf}[1]{\textbf{#1}}
\newcommand{\ovl}{\overline}
\newcommand{\Spec}{\operatorname{Spec}}
\newcommand{\K}{\operatorname{K_0}}
\newcommand{\witt}{\operatorname{W}}
\newcommand{\gw}{\operatorname{GW}}
\newcommand{\coh}{\operatorname{H}}
\newcommand{\dist}{\operatorname{dist}}
\newcommand{\cl}{\operatorname{Cl}}
\newcommand{\Vol}{\operatorname{Vol}}
\newcommand\tgg{\mathop{\rm tg}\nolimits}
\newcommand\ccup{\mathop{\cup}}
\newcommand{\id}{\operatorname{Id}}
\newcommand{\lcm}{\operatorname{lcm}}
\newcommand{\chr}{\operatorname{char}}
\newcommand{\rk}{\operatorname{rank}}
\DeclareMathOperator{\Coker}{Coker}
\DeclareMathOperator{\Ker}{Ker}
\newcommand{\im}{\operatorname{Im}}
\renewcommand{\Im}{\operatorname{Im}}
\newcommand{\Tr}{\operatorname{Tr}}
\newcommand{\re}{\operatorname{Re}}
\newcommand{\tr}{\operatorname{Tr}}
\newcommand{\ord}{\operatorname{ord}}
\newcommand{\Stab}{\operatorname{Stab}}
\newcommand{\orb}{\operatorname{\mathcal O}}
\newcommand{\Fix}{\operatorname{Fix}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\End}{\operatorname{End}}
\newcommand{\Aut}{\operatorname{Aut}}
\newcommand{\Inn}{\operatorname{Inn}}
\newcommand{\Out}{\operatorname{Out}}
\newcommand{\GL}{\operatorname{GL}}
\newcommand{\SL}{\operatorname{SL}}
\newcommand{\SO}{\operatorname{SO}}
\renewcommand{\O}{\operatorname{O}}
\renewcommand{\U}{\operatorname{U}}
\newcommand{\Sym}{\operatorname{Sym}}
\newcommand{\Adj}{\operatorname{Adj}}
\newcommand{\Disc}{\operatorname{Disc}}
\newcommand{\cnt}{\operatorname{cont}}
\newcommand{\Frob}{\operatorname{Frob}}

\newcommand{\di}{\mathop{\,\scalebox{0.85}{\raisebox{-1.2pt}[0.5\height]{\vdots}}\,}}

\newcommand{\ndi}{\mathop{\not\scalebox{0.85}{\raisebox{-1.2pt}[0.5\height]{\vdots}}\,}}
\newcommand{\nequiv}{\not \equiv}
\newcommand{\Nod}{\operatorname{\text{НОД}}}
\newcommand{\Nok}{\operatorname{\text{НОК}}}
\newcommand{\sgn}{\operatorname{sgn}}


\def\llq{\textquotedblleft} 
\def\rrq{\textquotedblright} 
\def\exm{\noindent {\bf Примеры:}}


\def\Cb{\ovl{C}}
\def\ffi{\varphi}
\def\pa{\partial}
\def\V{\bf V}
\def\La{\Lambda}
\def\eps{\varepsilon}
\def\del{\delta}
\def\Del{\Delta}
\def\A{\EuScript{A}}
\def\lan{\left\langle }
\def\ran{\right\rangle}
\def\bar{\begin{array}}
\def\ear{\end{array}}
\def\beq{\begin{equation}}
\def\eeq{\end{equation}}
\def\thrm{\begin{thm}}
\def\ethrm{\end{thm}}
\def\dfn{\begin{defn}}
\def\edfn{\end{defn}}
\def\lm{\begin{lem}}
\def\elm{\end{lem}}
\def\zd{\begin{zad}}
\def\ezd{\end{zad}}
\def\prdl{\begin{predl}}
\def\eprdl{\end{predl}}
\def\crl{\begin{cor}}
\def\ecrl{\end{cor}}
\def\rm{\begin{rem}}
\def\erm{\end{rem}}
\def\fct{\begin{fact}}
\def\efct{\end{fact}}
\def\enm{\begin{enumerate}}
\def\eenm{\end{enumerate}}
\def\pmat{\begin{pmatrix}}
\def\epmat{\end{pmatrix}}
\def\utv{\begin{utvr}}
\def\eutv{\end{utvr}}
\def\bupr{\begin{upr}}
\def\eupr{\end{upr}}
\def\cmm{\begin{comment}}
\def\ecmm{\end{comment}}

\frenchspacing
\righthyphenmin=2
%\usepackage{floatflt}
\captiondelim{. }




\begin{document}

\title{Конспект. Осень 2018}
\date{}
\author{}
\maketitle
\tableofcontents



\chapter{Полилинейная алгебра}
\section{Кватернионы}

Наша цель сейчас рассказать про геометрию трехмерного пространства используя при этом определённые алгебраические конструкции. А именно, ещё в XIX веке Уильям Роуэн Гамильтон стал искать аналогичную комплексным числам алгебраическую систему на трёхмерном пространстве.  
Однако, подходящий аналог удалось найти только в четырёхмерной ситуации.


Рассмотрим подпространство в алгебре матриц $M_2(\mb C)$ вида
$$\mb H = \left\{\pmat \alpha & \beta \\ -\ovl{\beta} & \ovl{\alpha} \epmat \right\}.$$
Базис этого пространства, как вещественного векторного пространства, состоит из матриц 
$$ 1=\pmat 1 & 0 \\ 0& 1 \epmat, i= \pmat i & 0 \\ 0& -i \epmat, j=\pmat 0& 1 \\ -1 & 0 \epmat, k=\pmat 0 & i \\ i & 0\epmat. $$ 
Покажем, что это вещественная подалгебра в $M_2(\mb C)$ и следовательно ассоциативное кольцо. 
Для этого достаточно показать, что произведение базисных снова лежит в $\mb H$. Имеем $$i^2=j^2=k^2=-1 \text{ и } ij=k=-ji,$$ откуда $$ik= iij=-j=jii=-ki \text{ и } jk=-jjk=-i=-kj.$$ Таким образом $\mb H$ образует ассоциативную алгебру размерности 4 над $\mb R$.
 
\dfn[Алгебра кватернионов] $\mb H$ называется алгеброй кватернионов. 
\edfn
Мы больше не будем думать про кватернионы как про матрицы, а будем записывать их через $i,j,k$. Именно так обычно их и вводят -- как формальный суммы $a+bi+cj+dk$, для произведения которых выполены тождества $i^2=j^2=k^2=-1$ и $ij=-ji=k$. Посмотрев на кватернионы как на матрицы мы сэкономили на доказательстве ассоциативности умножения.

\zd Алгебра кватернионов не снабжается структурой $\mb C$-алгебры.
\ezd



Рассмотрим произведение двух чисто мнимых кватернионов $uv=-\lan u,v\ran+[u,v]$. Его вещественная часть совпадает с минус скалярным произведением векторов. Про мнимую часть мы поговорим отдельно.

\dfn[Векторное произведение] Пусть $u,v \in \mb R^3$ два вектора. Тогда их векторным произведением называется вектор $[u,v]$.
\edfn

Если расписать в координатах $u=x_1i+x_2j+x_3k$ и  $v=y_1i+y_2j+y_3k$, то векторное произведение задаётся формулой

$$[u,v]= (x_2y_3-x_3y_2)i + (x_3y_1-x_1y_3)j + (x_1y_2- x_2y_1)k= \begin{vmatrix} i& j&k \\ x_1 & x_2 & x_3 \\ y_1 & y_2 & y_3 \end{vmatrix} $$

\rm Операция $(u,v) \to [u,v]$ является билинейной и антисимметричной, то есть $[u,u]=0$ и, следовательно, $[u,v]=-[v,u]$.
\erm


\dfn[Сопряжённый кватернион] Пусть $x= a+bi+cj+dk$ кватернион. Определим вещественную или скалярную часть $\Re x=a$ и мнимую или векторную часть $v=\Im x= bi+cj+dk$ кватерниона. Сопряжённым кватернионом называется $\ovl{x}= a-bi-cj-dk= \Re x - \Im x =a-v$. 
\edfn

\dfn[Норма кватерниона] Определим норму кватерниона как $$||x||=\sqrt{x\ovl{x}}=\sqrt{ a^2+b^2+c^2+d^2}=\sqrt{\ovl{x}x}.$$
\edfn 


Норма кватерниона, как и модуль комплексного числа всегда положительны для ненулевых элементов. Это позволяет заметить, что

\dfn[Обратный кватернион] Если $0\neq x \in \mb H$, то $x^{-1}=\frac{\ovl{x}}{||x||^2}$. 
\edfn

Таким образом мы получили первый (и для нас единственный) пример некоммутативного кольца с делением. Такие кольца называются телами. Напоминаю, что алгебра для нас ассоциативна и с единицей. Неассоциативные алгебры представляют интерес. Например, можно взять $\mb R^3$, где в качестве умножения взято векторное произведение. Это пример неассоциативной алгебры или, точнее, алгебры Ли. Мы не будем обсуждать неассоциатные алгебры в связи с тем, что им находится применение либо внутри физических дисциплин, либо внутри самой математики. 

Какие ещё свойства есть у отображения нормы? Если следовать параллели с комплексными числами, то стоит посмотреть, что происходит с нормой произведения. Для того, чтобы не обременяться вычислениями сделаем небольшой трюк и на секунду вспомним матричное представление кватернионов. Заметим, что на матричном языке, норма -- это $||x||=\sqrt{\det x}$, откуда получаем

\lm[Норма мультипликативна] $||xy||=||x||||y||$. В частности, $||x^{-1}||=||x||^{-1}$.
\elm

\crl[Сумма четырёх квадратов] В любом коммутативном кольце произведение $(a^2+b^2+c^2+d^2)(e^2+f^2+g^2+h^2)$ снова есть сумма четырёх квадратов.
\ecrl

Теперь легко доказать 
\lm Отображение $x \to \ovl{x}$ является антиизоморфизмом алгебр, то есть $\ovl{ab}=\ovl{b}\ovl{a}$.
\proof Линейной ясна. Пусть $x,y \neq 0$. Тогда $$\frac{\ovl{y}\,\ovl{x}}{||y||^2||x||^2}=y^{-1}x^{-1}=(xy)^{-1}=\frac{\ovl{xy}}{||xy||^2}.$$
\elm

На самом деле и здесь можно было воспользоваться матричным представлением. А именно, можно заметить, что операция сопряжения совпадает на этом языке с транспонированием и сопряжением соответствующей комплексной матрицы. Вернёмся теперь к векторному произведению.


\lm[Свойства векторного произведения] Верны следующие свойства\\
1) Для любых $u,v \in \mb R^3$ верно $u\bot [u,v]$. Точнее $$u[u,v]= -||u||^2v+ \lan u,v\ran u$$
2) $|| [u,v]||= ||u||||v|||\sin \ffi |$, где $\ffi$ --  это угол между $u$ и $v$.
\elm
\proof Для того, чтобы посчитать скалярное произведение $\lan u, [u,v]\ran$ необходимо посчитать скалярную часть $u[u,v]$. 
$$u[u,v]= u (uv+ \lan u,v \ran)= u^2 v+ \lan u,v \ran u= -||u||^2 v+ \lan u,v \ran u$$
Последнее выражение, очевидно, чисто векторное.
Теперь 
$$||[u,v]||^2= -[u,v][u,v]= (uv + \lan u,v\ran)(vu + \lan u,v\ran)= ||u||^2||v||^2+ \lan u,v\ran^2 + \lan u,v\ran (uv+vu)=||u||^2||v||^2 - \lan u,v\ran^2= ||u||^2||v||^2(1-\cos^2 \ffi)$$
\endproof

\dfn Обозначим за $\mb H_{1}$ группу кватернионов, по норме равных единице.
\edfn

\thrm Отображение $\mb H_{1}\to \GL_3(\mb R)$ заданное по правилу $x\to (y \to xyx^{-1})$ корректно определено и даёт сюръективный  гомоморфизм из группы кватернионов единичной нормы в $\SO_3(\mb R)$. Ядро этого гомоморфизма состоит из $\{\pm 1\}$. Точнее, если единичный кватернион $x$  представим в виде $x=a+bv$, то соответствующее вращение есть вращение относительно  оси $\lan v \ran$ на угол $2\ffi$, где $\cos \ffi= a$, $\sin \ffi= b$ или тождественное преобразование в случае $v=\pm 1$.
\ethrm
\proof Рассмотрим преобразование $L_x \colon \mb H \to \mb H$ вида $y \to xyx^{-1}$ Прежде всего покажем, что мы получили ортогональное преобразование $\mb R^4$. Имеем
 $$||xvx^{-1}||=||v||.$$
Теперь заметим, что преобразование $L_x$ сохраняет на месте вектор 1 и, следовательно, его ортогональное дополнение, то есть $\mb R^3$. Таким образом $L_x$ ограничивается на $\mb R^3$. Далее, очевидно, $L_xL_y= L_{xy}$. Осталось посчитать ядро гомоморфизма и явный вид отображения $L_x$. Заметим, что если $x=a+bv$, то $L_x$ оставляет $v$ на месте. Действительно, при $b\neq 0$ 
$$xbvx^{-1}=x(x-a)x^{-1}= x-a=bv.$$
Вычислим угол поворота. Для этого рассмотрим нормированный вектор  $u\bot v$ и $[u,v]$, которые образуют ортонормированный базис дополнения и посчитаем $xux^{-1}$ и $x[u,v]x^{-1}$. 
$$xux^{-1}=(a+bv)u(a-bv)= (a+bv)(au-[u,bv])=a^2u -ab[u,v]+ab[v,u]- b^2[v,[v,u]]=(a^2-b^2)u-2ab[u,v]$$
$$x[u,v]x^{-1}=(a+bv)[u,v](a-bv)= (a[u,v]+bu)(a-bv)=a^2[u,v]+abu-ab[u,v]v-b^2uv=(a^2-b^2)[u,v]+2abu $$
\endproof


\zd
Покажите, что отображение $(x,y) \to (z \to xzy^{-1})$ задаёт сюръективный гомоморфизм из декартового квадрата группы единичных кватернионов в группу $\SO_4(\mb R)$ с ядром $\{(1,1),(-1,-1)\}$.
\ezd

Обсудим теперь некоторое применение кватернионов.



\section{Задачи на максимизацию}

Теперь обратимся к вопросам, связанным с вещественными самосопряжёнными операторами. Для этого заметим, что с каждым самосопряжённым оператором $L$ на евклидовом пространстве можно связать билинейную симметричную  форму $\lan x,Ly\ran$ или, что эквивалентно, квадратичную форму $\lan x,Lx\ran$. Безусловно по квадратичной форме можно обратно восстановить оператор. 

Рассмотрим один из вопросов, связанных с такой конструкцией, а именно, рассмотрим задачу о нахождении нормы линейного оператора $L \colon U \to V$ между двумя евклидовыми пространствами. Для того, чтобы найти  норму необходимо найти $$\max_{x\neq 0}\sqrt{\frac{\lan Lx,Lx\ran}{\|x\|^2}}=\sqrt{\max_{x\neq 0}\frac{\lan L^*Lx,x\ran}{\|x\|^2}}=\sqrt{\max_{\|x\|=1} \frac{\lan L^*Lx,x\ran}{\|x\|^2}}.$$
Таким образом, нахождение нормы оператора свелось к задаче максимизации квадратичной формы на единичной сфере. Заметим, что максимум действительно достигается благодаря компактности сферы.

Оказывается, что довольно легко найти максимум или минимум квадратичной формы на сфере.



\thrm Пусть $V$ -- евклидово пространство, $A$ -- самосопряжённый оператор на $V$, а $q(x)=\lan x,Ax\ran$ -- соответствующая квадратичная форма. Тогда 
$$\max_{ x\in V } \frac{q(x)}{||x||^2}=\max_{\substack{ x\in V \\ ||x||=1}} q(x)=\lambda_1,$$
 где $\lambda_1$ - наибольшее собственное число оператора $A$ и достигается на собственном векторе $v_1$, соответствующему $\lambda_1$. Аналогично минимум равен минимальному собственному числу $A$. 
\proof
Пусть $v=\sum c_i e_i$, причём $1=||v||^2=\sum c_i^2$. Тогда $\lan Av,v\ran = \sum c^2_i \lambda_i $, что меньше $\lan A e_1,e_1\ran= \lambda_1= \sum \lambda_1 c_i^2$.
\endproof
\ethrm

Эта теорема, кроме, собственно, решения задачи, даёт геометрическую характеризацию первого собственного числа. Вопрос: можно ли аналогично охарактеризовать другие собственные числа? Ответ получается не таким простым, но, тем не менее, полезным.

\thrm[Куранта-Фишера] Пусть $q(x)=\lan x, Ax\ran$. Тогда $k$-ое по убыванию собственное число $\lambda_k$ для $A$ есть 
$$ \lambda_k=\max_{\dim L=k} \min_{\substack{ x\in L \\ ||x||=1}} q(x) = \min_{\dim L=n-k+1} \max_{\substack{ x\in L \\ ||x||=1}} q(x).$$
Причем максимум достигается на инвариантном подпространстве, содержащем собственные вектора для $\lambda_1,\dots,\lambda_k$.
\ethrm
\proof Пусть $U$ --- подпространство на котором достигается максимум, причём допустим, что максимум больше $\lambda_k$. Тогда рассмотрим подпространство $W=\lan v_k,\dots,v_n\ran$, где $v_i$ --- собственный вектор соответствующий $i$-ому по убыванию собственному числу. Заметим, что $U\cap W=\{0\}$, так как на $W$ форма принимает значения меньше или равные $\lambda_k$, а на $U$ -- строго большие. Однако $\dim W=n-k+1$. Приходим к противоречию с подсчётом размерности пересечения. 
\endproof


Введём определение:
\dfn
Пусть $q$ -- квадратичная форма на евклидовом пространстве. Рассмотрим ортонормированный базиc $u_i$ пространства $V$. Тогда положим 
$$\Tr q= \sum q(u_i).$$ Если в базисе $u_i$ форме $q(x)=x^{\top} Ax $ соответствует симметричная матрица $A$, то $\Tr q(x)=\Tr(A)$.
\edfn

\rm Определение не зависит от выбора ортонормированного базиса. Действительно, если замена координат ортогональна, то матрица $q$ в новой системе координат имеет вид $C^{\top}AC=C^{-1}AC$. Осталось заметить, что след последней матрицы очевидно равен следу $A$.
\erm

\rm Если форме $q$ соответствует самосопряжённый оператор $A$, то $\Tr q=\sum \lambda_i$, где $\lambda_i$ -- собственные числа $A$.
\erm

\crl Пусть $U$ некоторое подпространство, а $q(x)=x^{\top} Ax$. Пусть собственные числа $A$ --- это $\lambda_i$, а собственные числа оператора, соответствующего $q(x)|_U$ -- это $\mu_i$ упорядоченные по убыванию. Тогда 
$$\lambda_{i+n-m}\leq \mu_i\leq \lambda_i.$$  
\proof Заметим, что
 $$\mu_i=\max_{\substack{L\leq U\\ \dim L=i}} \min_{\substack{ x\in L \\ ||x||=1}} q(x),$$
что очевидно меньше, чем 
$$\max_{\substack{L\leq V\\ \dim L=i}} \min_{\substack{ x\in L \\ ||x||=1}} q(x)=\lambda_i.$$ Неравенство в другую сторону получается из второго описания в теореме Куранта-Фишера.
\endproof
\ecrl




\crl Пусть $q(x)=x^{\top} Ax$, $U$ --- некоторое подпространство, $\dim U=k$. Пусть собственные числа $A$ --- это $\lambda_i$. Тогда $$\Tr q|_U\leq \sum_{i=1}^k \lambda_i= \Tr q|_{V_k},$$
где $V_k$ подпространство натянутое на первые $k$ собственных векторов $q$.
\proof Нам известны неравенства на собственные числа $\mu_i$, ограничения $q|_U$. А именно, $\mu_i\leq \lambda_i$. Но тогда и $$\sum_{i=1}^k \mu_i \leq \sum_{i=1}^k \lambda_i.$$
\endproof
\ecrl 








\section{Метод главных компонент}

Рассмотрим следующую задачу: имеется массив данных --- набор векторов $x_1,\dots,x_s \in V$, где $V$ -- это евклидово пространство размерности $n$. Подразумевается, что точек очень много. Предположим, что при идеальных измерениях между координатами этих векторов есть линейные зависимости. Все отклонения от этой погрешности вызваны небольшими погрешностями. Задача состоит в том, чтобы восстановить линейную зависимость. 


Переформулируем задачу геометрически. Пусть наши вектора удовлетворяют линейным условиям $Ax_i=b$ для некоторой матрицы $A$ ранга $n-k$. Это значит, что они лежат в аффинном подпространстве $\Ker A + a_0$ размерности $k$. Если же нам даны вектора с погрешностями, то задачу таким образом можно поставить в виде: найти аффинное подпространство размерности $k$ наиболее близкое к данным точкам $x_1,\dots,x_s$. Понятие <<Наиболее близкое>> требует конкретизации. Вообще говоря, тут есть выбор. Мы будем считать, что подходящее пространство $W=L+a_0$ должно давать минимум следующего выражения:
$$\sqrt{\sum_{i=1}^s \rho(x_i,W)^2} \to \min.$$
Совершенно ясно, что корень квадратный тут для красоты, и минимизировать нужно $\sum_{i=1}^s \rho(x_i,W)^2$.

Прежде всего установим, что какой бы <<минимайзер>> $W=L+a_0$ мы не нашли, в $W$ всегда будет лежать среднее $\frac{1}{s}\sum_{i=1}^s x_i$ и, следовательно, в качестве $a_0$ всегда можно взять среднее.

Действительно, выпишем условие $\sum_{i=1}^s \rho(x_i-a_0, L)^2=\sum ||pr_{L^{\bot}} (x_i-a_0)||^2$  минимально.  Продифференцируем по координатам $a_0$. Получим $$\sum -2pr_{L^{\bot}} x_i + 2 pr_{L^{\bot}} a_0=0$$
 Это условие означает, что проекции $a_0$ и среднего $\frac{1}{s}\sum x_i$ на подпространство $L^{\bot}$ совпадают. То есть эти две величины отличаются на элемент $L$. Тогда среднее лежит в $W$. 

Итак, вычтя из всех $x_i$ их среднее можно считать $a_0=0$, а все точки $x_i$ удовлетовряют равенству $\sum_{i=1}^s x_i=0$. Замечу, что это равенство нигде в дальнейшем не будет использовано. Благодаря такой замене мы свели задачу к поиску подпространства $L$ размерности $k$, которое минимизирует 
$$\sum_{i=1}^s \rho(x_i, L)^2=\sum_{i=1}^s ||pr_{L^{\bot}} (x_i)||^2.$$

Воспользуемся тем, что $||x||^2=||pr_L x||^2+||pr_{L^{\bot}} x||^2$ или $||x||^2-||pr_L x||^2=||pr_{L^{\bot}} x||^2$. Тогда получаем, что
$$\sum_{i=1}^s ||pr_{L^{\bot}}(x_i)||^2=\sum_{i=1}^s ||x_i||^2-||pr_L x_i||^2$$
должно быть минимально. Тогда сумма $\sum_i ||pr_L x_i||^2$ должна быть максимальна.


Для того чтобы посчитать проекцию выберем в $L$ ортонормированный базис $u_1,\dots,u_k$. Тогда перепишем
$$\sum_{i=1}^s ||pr_L x_i||^2=\sum_{i=1}^s\sum_{j=1}^k \lan x_i,u_j\ran^2=\sum_{j=1}^k \sum_{i=1}^s \lan x_i,u_j\ran^2.$$

Внутренняя сумма теперь есть значение некоторой квадратичной формы на векторе $u_j$. Разберёмся какой. Рассмотрим матрицу $X$ размера $s\times n$, чьи строки это  вектора $x_i$ $i\in\ovl{1,s}$. Тогда вектор $d=Xu_j$ состоит из скалярных произведений  $\lan v_i, u_j\ran$. Тогда выражение $\lan d,d\ran = (u_jX^{\top})Xu_j = \sum_{i=1}^s \lan x_i,u_j\ran^2$, то есть как раз тому, что участвует в нашей сумме. Рассмотрим симметричную матрицу $A=X^{\top}X$ и обозначим соответствующую ей форму за $q$. Тогда нам надо минимизировать выражение
$$\sum_{j=1}^k q(u_j).$$



Таким образом мы ищем максимум $\Tr q_{L}$ по всем подпространствам $L$ размерности $k$, где форма $q$ соответствует матрице $X^{\top} X$. 
Сформулируем теперь ответ. 


\thrm  Пусть есть набор векторов $x_1,\dots,x_s \in V$. Определим симметричную, положительно определённую матрицу $A$, как $A=X^{\top}X$, где строчки матрицы $X$ -- это вектора $x_i$. Тогда минимум по всем аффинным подпространствам $V$ размерности $k$ выражения $\sum_{i=1}^s \rho(x_i,W)^2$ достигается при $a_0=\frac{1}{s}\sum x_i$  и $L=\lan v_1,\dots,v_k\ran$, где $v_i$ --- собственные вектора $A$, причём соответствующие собственные числа упорядочены по убыванию. 
\ethrm

При вычислении с помощью метода главных компонент часто используют несколько другие конструкции. В частности, в методе главных компонент возникает матрица $X^{\top}X$ и её собственные числа. Про них поговорим подробнее.

\dfn[Сингулярные значения] Пусть $A$ -- линейное отображение $A\colon U \to V$ между евклидовыми пространствами. Тогда сингулярными значениями $A$ называются числа $\sigma_i=\sqrt{d_i}$, где $d_i>0$ -- положительные собственные числа оператора $A^*A \colon V \to V$. Если же говорить на языке матриц, то для матрицы $X$ её сингулярными значениями будут корни из собственных чисел $X^{\top}X$. 
\edfn

На самом деле мы не обсуждали определение сопряжённого линейного отображения, а только сопряжённого оператора. Напишу немного об этом.

\dfn Пусть $A$ -- линейное отображение $A\colon U \to V$ между евклидовыми пространствами. Тогда сопряжённым отображением к $A$, называется такое линейное отображение $A^{*}$, что $\lan A^*x,y\ran = \lan x,Ay\ran$ для всех $x\in V$ и $y \in U$.
\edfn

\thrm Сопряжённое линейное отображение единственно. Более того, если в $U$ и $V$ выбрать ортонормированные базисы, то матрица сопряжённого отображения в этих базисах будет равна транспонированной матрице исходного.
\proof Достаточно доказать последнюю часть, чтобы показать единственность и существование. Выберем ортонормированные базисы в $U$ и $V$ -- $u_j$ и $v_i$. Обозначим матрицу $A$ в этом базисе за $X$, а кандидата на $A^*$ за $Y$. Тогда для равенства из определения сопряжённости необходимо и достаточно, его выполения на базисных. Иными словами необходимо и достаточно, чтобы $\lan X^{*}e_i,e_j\ran=\lan e_i,Xe_j\ran$. Но первая часть даёт $X^{*}_{ji}$, а вторая -- $X_{ij}$. Итого необходимо и достаточно, чтобы $X^{*}=X^{\top}$.   
\endproof
\ethrm

Теперь обсудим важную конструкцию, проясняющую геометрический смысл сингулярных значений.


\thrm[SVD разложение] Пусть $A$ -- линейное отображение $A\colon U \to V$ между евклидовыми пространствами. Тогда существуют такие ортонормированный базисы $U$ и $V$, что матрица $A$ имеет вид 
$$\pmat \sigma_1 &\dots& 0 & 0\\
 \vdots & \ddots &\vdots & \vdots\\
 0 & \dots & \sigma_r & 0\\
 0 &  \dots & 0 & 0 \epmat,$$
 где $r$ -- ранг $A$, числа $\Sigma=\sigma_1, \dots, \sigma_r$ её сингулярные значения.
На языке матриц это означает, что для любой матрицы $X \in M_{m\times n}$ существуют матрицы $L$ -- размера $m$ и $R$ -- размера $n$,  что
$$X= L \Sigma R,$$
 с теми же условиями на $r$ и $\sigma_i$.
 
\proof Рассмотрим оператор $B = A^{*}A$. Тогда существуют ортонормированный базис $e_1,\dots,e_n$ в котором оператор $B$ диагонален, с неотрицательными числами на диагонали $d_1\geq\dots\geq d_n\geq 0$. Имеем  $d_i=\sigma_i^2$ для единственного положительного $\sigma_i$. 
Посмотрим на вектора $Ae_i \in U$. Они ортогональны. Действительно
$$\lan Ae_i, Ae_j\ran = \lan A^{*}Ae_i,e_j \ran = \lan d_i e_i,e_j\ran,$$
что равно нулю, если $i\neq j$. В случае $i=j$ получаем $||e_i||^2=d_i$. Возьмём 
$$f_i=\frac{Ae_i}{\sqrt{d_i}}$$
и дополним этот набор до ортонормированного базиса пространства $U$. Итого имеем $e_1,\dots,e_n$ ортонормированный базис $U$ и $f_1,\dots,f_m$ -- ортонормированный базис $V$.
Посмотрим матрицу $A$ в этих базисах. По определению $Ae_i=\sqrt{d_i}f_i$. Это и даёт требуемый вид матрице оператора $A$
Напоследок осталось решить вопрос, как выглядит матрица $R$. В нашей конструкции матрица $R$ есть матрица замены из стандартного базиса в базис из собственных векторов $e_i$ матрицы $X^{\top}X$. Если за $C$ обозначить матрицу из столбцов $e_i$, то $R=C^{-1}$, но $C$ ортогональна и поэтому можно написать $R=C^{T}$, то есть строки $R$ -- собственные вектора $X^{\top}X$. Часто эти вектора называют правыми сингулярными векторами $X$.

\endproof
\ethrm

\zd Получите аналогичное описание для $L$. Покажите так же, что ничего кроме $\Sigma$ в аналогичном разложении получится не может.
\ezd

SVD-разложение используется в практическом решении задачи из метода главных компонент и позволяет сразу найти не только пространство, но и проекцию начальных точек на него. Формализуется это так: рассмотрим матрицу $X$, чьи строки равны $x_i^{\top}$. Тогда если все её строки заменить на их проекции на оптимальное подпространство $L$, то получится матрица ранга $k$ или меньше. Эта матрица будет ближайшей к исходной в смысле вот такой вот матричной нормы, называемой, нормой Фробениуса 
$$||X||_F=\sqrt{\sum_{i,j} a_{ij}^2}=\sqrt{\Tr X^{\top}X}.$$
Таким образом нахождение проекций точек можно переформулировать, как нахождение ближайшей к матрице $X$ матрице ранга меньше или равного $k$. Это легко сделать, зная SVD-разложение

\thrm Пусть $X\in M_{m\times n}(\mb R)$. И SVD-разложение $X$ имеет вид $X=L\Sigma R$, где на диагонали $\Sigma$ стоят $\sigma_1,\dots,\sigma_r$ и нули. Тогда наилучшим приближением ранга $k$ в смысле нормы Фробениуса к матрице $X$ будет матрица $X^{(k)}=L\Sigma^{(k)}R$, где на диагонали $\Sigma^{(k)}$ стоят $\sigma_1,\dots,\sigma_{k}$ и нули.
\proof Для того, чтобы найти матрицу $X^{(k)}$ необходимо спроецировать строки $X$ на подпространство $L=\lan v_1^{\top},\dots,v_k^{\top}\ran$, где $v_i$ ортонормированный базис из собственных векторов $X^{\top}X$.  Вспомним, что строки $R$ есть $v_i^{\top}$. Для того, чтобы спроецировать одну строку $a$ на пространство $V^{(k)}$ необходимо вычислить сумму $\sum_{i=1}^k (av_i)v_i^{\top}$. Применив это целиком к матрице $X=L\Sigma R$ получим 
$$X^{(k)}=\sum_{i=1}^k Xv_iv_i^{\top}=L\Sigma \left(\sum_{i=1}^k Rv_iv_i^{\top}\right).$$
Вычислим последнюю сумму. Эта сумма считает проекции строк $R$ на $L$. Но первые $k$ строк лежат в $L$, а остальные ортогональны $L$. Итого имеем
$$R^{(k)}=\sum_{i=1}^k Rv_iv_i^{\top} = \pmat v_1^{\top} \\ \vdots \\ v_k^{\top} \\ 0 \\ \vdots \\ 0 \epmat.$$
Осталось заметить, что $\Sigma^{(k)} R= \Sigma^{(k)}R^{(k)}=\Sigma R^{(k)}$.
\endproof
\ethrm 

SVD-разложение используется в разных задачах, в том числе и для сжатия изображений.  Для простоты рассмотрим случай квадратного $n \times n$ чёрно белого изображения. Сделаем из него вещественную матрицу $X$ размера $n \times n$ и найдём SVD-разложение $L \Sigma K$. Тогда приближение $X^{(k)}$ задаётся $L\Sigma^{(k)}R$. Однако, как мы уже заметили, вместо матрицы $R$ можно взять матрицу $R^{(k)}$. Аналогично вместо $L$ можно взять $L^{(k)}$ -- выкинув из $L$ последние $n-k$ столбцов. Для хранения матрицы $\Sigma^{(k)}$ нужно $k$ параметров, для матриц $L^{(k)}$ и $R^{(k)}$ по $kn$ параметров. Итого нужно $2kn+k$ параметров. Однако чтобы не хранить отдельно $\Sigma$ её можно домножить на $L$ и хранить $L\Sigma$. В таком случае необходимо $2kn$ параметров. При $k<\frac{n}{2}$ это даёт эффект сжатия. 

Однако, это не предел. Посмотрим, сколько параметров нужно, чтобы задать $X$ -- матрицу ранга $k$. Пусть главный минор размера $k$ матрицы $X$ не ноль (априори мы знаем, что какой-то минор такого размера не ноль). Тогда для $j$-ой строки матрицы, начиная с номера $j \geq k+1$ есть набор чисел $a_{1,j},\dots,a_{k,j}$, которые есть коэффициенты в линейной комбинации дающей из первых строк $j$-ую. Аналогично для столбцов. Такой набор данных задаётся $k^2+ 2k(n-k)=2kn-k^2$ параметрами. Осталось заметить, что всегда $2kn - k^2\leq n^2$ так как $0\leq n^2-2kn+k^2=(n-k)^2$. Если невырожденным оказался не главный минор, то дополнительно нужно задать $2k$ дискретных параметров задающий номера строк и столбцов невырожденного минора.



\section*{Дополнительно: поиск угла между подпространствами}
Попробуем решить другую задачу -- определить, что такое угол между подпространствами и понять, как его найти. 

\dfn
Пусть $U$ и $W$ два подпространства  евклидового пространства. Определим косинус угла между ними как 
$$\cos \angle U,W= \sup_{\substack{ x\in U\\ y\in V}} \frac{\lan x,y\ran}{||x|| ||y||}.$$
\edfn

\rm Если два подпространства пересекаются, то угол между ними по этому определению равен 0. Если хочется, чтобы угол не был равен 0 для неравных пространств, то разумно посмотреть ортогональные дополнения $U$ и $W$ к пересечению $U\cap W$ и посчитать угол между ортогональными дополнениями. 
\erm

\rm Можно переписать выражение для косинуса как $$\cos \angle U,W= \sup_{ x\in U} \cos \angle x, V = \sup_{x\in U} \frac{||pr_V x||}{||x||}= \sqrt{ \sup_{\substack{x\in U\\ ||x||=1}} ||pr_V x||^2} .$$
\erm

С последним выражением легко работать, потому что $||pr_V x||^2$ -- это квадратичная форма на $U$.

Допустим мы хотим максимизировать указанное выражение. Выберем на $U$ ортонормированный базис. Посчитаем матрицу формы $||pr_V x||^2$ по формуле 
$$a_{ij}= \lan pr_V u_i, pr_V u_j\ran.$$

Тогда максимум выражения под корнем равен $\lambda_{max}$ -- максимальному собственному числу $A$ и достигается на соответствующем векторе $v_{max}$. Ответ: $\sqrt{\lambda_{max}}$

\rm Получилось, что косинус угла -- это норма оператора проекции с одного подпространства на другое. Это не совсем то, что нас интересует в общем случае, например для гиперплоскостей. Дело в том, что для них ответ всегда 1, так как гиперплоскости заведомо пресекаются по подпространство ненулевой размерности (кроме как в двумерной ситуации). Вектора из пересечения проецируются в себя, что показывает, что норма оператора проекции равна единице. В этом случае стоит заменить оба подпространства на их ортогональные дополнения к пересечению. Это тоже самое, что найти первое неединичное собственное число для формы  $\lan pr_V u_i, pr_V u_j\ran$ на $U$.
\erm




\section{Спектры графов}

\dfn
Для каждого графа $G$ можно построить  несколько  различных матриц, которые кодируют его структуру. Прежде всего это три квадратные матрицы  размера $n\times n$, где $n$ -- это число вершин $G$. 
Первая -- матрица смежности  $A(G)$, которая полностью определяет граф $G$
$$a_{ij}=\begin{cases} 1, \text{ если вершины $i$ и $j$ соединены ребром}\\
0, \text{ иначе }
\end{cases}.$$

Так же нам уже встречалась матрица случайного блуждания  $P(G)$

$$P_{ij}=\begin{cases}
\frac{1}{d_j}, \text{ если есть ребро $j\to i$}\\
1, \text{ если из вершины не исходит рёбер} \\
0, \text{ иначе }
\end{cases}.$$
Кроме того, полезна бывает матрица инцидентности $B(G)$ размера $n\times m$, где $m$ -- число рёбер.
\edfn

В прошлом семестре мы с вами поняли, что для понимания того, как устроен предел последовательности $P^nv$, необходимо представлять себе как устроены собственные числа матрицы $P$. Прежде всего мы с вами понимали, что у матрицы $P$ есть собственное число 1. Однако встаёт несколько вопросов:\\
1) Какова кратность единицы, как собственного числа?\\
2) Есть ли другие собственные числа, равные единице по модулю?\\
3) Если $Pv=v$, то мы хотели бы интерпретировать $v$ как вектор весов для вершин графа. Верно ли, что $v$ можно выбрать положительным? Сколько таких независимых $v$?

Понятно, что в общем случае ответ на первые два вопроса <<нет>>.

\exm \\
1) Рассмотрим граф 
\begin{center}
\begin{tikzpicture}

\begin{comment}
\draw [fill] (0,0) circle [radius=0.05];
\draw [fill] (1,0.5) circle [radius=0.05];
\draw [fill] (1,-0.5) circle [radius=0.05];
\end{comment}

\node (A) at (0,0) {3};
\node (B) at (1,0.5) {1};
\node (C) at (1,-0.5) {2};
\path[->,font=\scriptsize,>=angle 60]
(A) edge (B)
(A) edge (C);
\end{tikzpicture}
\end{center}
У его матрицы $P$ очевидно есть два собственных вектора $(1,0,0)$ и $(0,1,0)$ с собственным числом 1.\\
2) Рассмотрим граф $C_n$ -- цикл длины $n$. Его спектр -- это корни степени $n$ из единицы.\\

Сейчас мы докажем, что при некоторых предположениях на матрицу для неё ответы на все три вопроса оказываются положительными. Эти предположения не будут выполнены для матриц $A(G)$ и  $P(G)$ непосредственно, однако мы тем не менее сможем извлечь пользу.

\dfn Назовём матрицу $A$ положительной (не путать с положительно определённым оператором), если все её элементы $A_{ij}$ строго положительны. Будем писать в этом случае $A>0$.
\edfn

\dfn Назовём матрицу  $A$ не отрицательной, если $A_{ij}\geq 0$. Обозначение $A \geq 0$.
\edfn

\thrm[Перрон, 1907] Если матрица $A$ положительна, то наибольшее по модулю собственное число $A$ единственное и является вещественным и положительным. Это собственное число не является кратным корнем характеристического многочлена. Собственный вектор для этого собственного числа положителен.
\ethrm
\proof Пусть $\lambda$ -- наибольшее по модулю собственное число и $Ax=\lambda x$. Можно считать, что $|\lambda|=1$. Тогда покажем, что $A|x|=|x|$.

Прежде всего мы имеем цепочку неравенств $|x|=|Ax|\leq |A||x|=A|x|$, где все неравенства подразумеваются покомпонентными. Обозначим за $z=A|x|$. Это вектор состоящий из положительных координат и рассмотрим вектор $y=z-x$. Вектор $y$ неотрицателен. При этом если $y=0$, то мы доказали то, что хотели. Предположим, что есть координата $y_i>0$. Тогда $Ay$ -- положительный вектор, то есть существует такое $\eps>0$, что $Ay>\eps z$. Распишем это неравенство: $Az - z= Az-A|x|> \eps z$ или же $\frac{A}{1+\eps}z>z$. Ввиду положительности правой и левой части мы без сомнений можем применить оператор $\frac{A^n}{(1+\eps)^n}$ к правой и левой части и получить верное неравенство. Итого имеем цепочку 
$$\frac{A^n}{(1+\eps)^n}z>\frac{A^{n-1}}{(1+\eps)^{n-1}}> \dots > z.$$
Но оператор $\frac{A}{1+\eps}$ имеет собственные числа по модулю меньшие 1 и поэтому, как мы знаем с прошлого семестра, предел левого выражения равен 0. Противоречие!

Итак, в частности, единица собственное число. Покажем теперь, что нет отличных от единицы собственных чисел. Пусть $\lambda$ собственное число $A$ с $|\lambda|=1$ и $x$ -- соответствующий собственный вектор. Тогда $A|x|=|x|=|Ax|$. Заметим, что все координаты $x$ отличны от нуля. Рассмотрим $i$-ую координату. Имеем $\sum A_{ij}|x_j|=x_i=|\sum A_{ij}x_j|$. Посмотрим на это равенство как на равенство нормы векторов в $\mb R^2$. Хорошо известно, что сумма норм больше или равна нормы суммы и равенство достигается тогда и только тогда, когда вектора сонаправлены. Итого координаты $x_i$ должны быть сонаправлены, но это означает, что $x=e^{i\ffi} |x|$ и следовательно $\lambda=1$. 

Покажем, что единица не кратный корень. Действительно, пусть есть два собственных вектора $x_1$ и $x_2$. Тогда подберём $c$, так что $x_1-cx_2$ имеет нулевую координату. Получаем противоречие, так как $|x_1-cx_2|$ неотрицательный вектор для 1, но при этом с нулевой координатой. Осталось разобрать случай, когда $x_2$ присоединён к $x_1>0$, то есть $Ax_2=x_2+x_1$. Тогда имеем $A^nx_2=x_2 +nx_1$. Это значит, что какие-то коэффициенты $A^n$ растут по крайней мере линейно по $n$. Но тогда и коэффициенты $A^nx_1=x_1$ тоже растут по крайней мере линейно, что очевидно не так.
\endproof

Так же бывает полезно ещё одно утверждение. 
\lm Пусть $A>0$, $\lambda$ -- максимальное по модулю собственное число. Если у матрицы $A$ есть собственный вектор $y\geq 0$, то $y$ собственный вектор для числа $\lambda$
\elm
\proof Рассмотрим матрицу $A^{\top}$. У неё есть положительный  собственный вектор $x$, соответсвующий собственному числу $\lambda$. Пусть $\mu$ -- собственное число для $y$. Тогда 
$$\lambda x^{\top}y= x^{\top}Ay=x^{\top}\mu y=\mu x^{\top}y.$$
Так как $x^{\top}y >0$, то $\lambda=\mu$.
\endproof


Вообще говоря матрица $P(G)$ имеет довольно много нулевых компонент. И, строго говоря, теорема Перрона не может быть верна для $P(G)$ всегда. Как же она может помочь? Для этого мы схитрим и немного поменяем задачу. А именно, рассмотрим матрицу $$P_{\alpha}(G)=(1-\alpha) P(G) + \alpha\tfrac{1}{n}J_n,$$
где $J_n$ -- матрица из одних единиц, а $\alpha \in (0,1)$. Тогда матрицы $P_{\alpha}(G)$ являются положительными. С точки зрения блуждающего пользователя это означает, что у него есть два режима -- первый, в котором он находится с вероятностью $1-\alpha$ -- это режим брожения по ссылкам, а второй режим -- переход на случайную страницу. Для матрицы $P_{\alpha}(G)$ выполнены условия теоремы и поэтому она имеет единственное не кратное максимальное собственное число, которое положительно и соответствующий собственный вектор положителен. Покажем, что это собственное число равно 1.

Для этого рассмотрим матрицу $P_{\alpha}(G)^{\top}$. У этой матрицы есть положительный собственный вектор $(1,\dots,1)$ с собственным числом 1. Но тогда это максимальное по модулю собственное число для $P_{\alpha}(G)^{\top}$ и следовательно для $P_{\alpha}(G)$. 

То, что у $P_{\alpha}(G)$ все собственные числа по модулю меньше единицы означает, что $P_{\alpha}(G)^kv \to cx$, при $k \to \infty$, где $x$ -- положительный вектор с собственным числом равным 1. Это позволяет приближённо найти $x$, что даёт желаемое распределение весов. Практически для этого можно взять $k\sim \log n$. Это позволяет заметно сэкономить на вычислениях по сравнению с теоретическим нахождением собственных векторов. Изучая предел $P_{\alpha}(G)$ при $\alpha \to 0$ можно получить информацию и про исходную матрицу.


Теперь переключимся на основной случай, который будем рассматривать -- случай неориентированных графов. В этой ситуации особую роль играет матрица $A(G)$.


\dfn Спектр графа -- это спектр его матрицы смежности $A(G)$.
\edfn


Для начала разберёмся с оценками и свойствами собственных чисел матрицы смежности. Здесь нам пригодится теорема Перрона. 


\lm Пусть граф $G$ связен. Тогда его максимальное собственное число положительно, не кратно и соответствующий собственный вектор имеет положительные координаты. Более того, все собственные числа графа по модулю меньше чем максимальная степень $d_{max}$. Граф $G$ регулярен тогда и только тогда, когда $d_{max}$ -- это его собственное число.
\elm
\proof Прежде всего отметим, что все собственные числа $G$ вещественные и максимальное собственное число положительно так как $\Tr A(G)=0$. Рассмотрим теперь матрицу $(A+\eps I)^{n-1}$. Это положительная матрица. Действительно в $(A+\eps I)^{n-1}_{ij}$ входит слагаемое $\eps^{n-1-l}$, где $l$ -- длина пути между $i$ и $j$. То же можно сказать и про большую степень $A+\eps I$. Максимальное с.ч. $A$ соответствует максимальному с.ч. $(A+\eps I)^l$ по крайней мере, если $\eps$ очень большое. Но тогда соответствующий собственный вектор $v$ положителен и максимальное собственное число $A+\eps I$ и, следовательно, $A$ не кратно. Далее $v$ положительный собственный вектор для всех $(A+\eps I)^{l}$, откуда получаем, что максимальное с.ч. у всех $(A+\eps I)^{l}$ наибольшее по модулю $(\lambda_1+\eps)^l>|\lambda_i+\eps|^l$. Переходя к пределу при $\eps \to 0$ получаем, что $\lambda_1^l \geq |\lambda_i|^l$. Осталось извлечь корень.

Почему же $\lambda_1 \leq d_{max}$? Пусть $x$ -- собственный вектор для числа $\lambda_1$. Тогда $Ax=\lambda_1 x$. Посмотрим, насколько мог измениться $x$ при домножении на $A$. Рассмотрим максимальную координату $x_i$. Имеем $\lambda_1 x_i= \sum a_{ij}x_j\leq d_{max} x_i$.

Предположим, что $d_{max}$ собственное число. Тогда в указанном выше неравенстве достигается равенство, то есть $x_i=x_j$ для соседних вершин. Но это значит, что вектор $(1,\dots,1)$ собственный, что бывает только в случае регулярного графа. 
\endproof


\exm \\
1) Спектр полного графа $K_n$ равен $n-1$ , $-1, \dots,-1$.\\
2) Спектр цикла длины $n$ равен $2\cos(\frac{2\pi l}{n})$.\\
Попробуем разобрать ещё один пример:

\dfn Сильно регулярный граф с параметрами $n$, $k$, $\lambda$ и $\mu$ это $k$-регулярный граф на $n$ вершинах, такой что любые две смежные вершины имеют $\lambda$ соседей, а любые две несмежные -- $\mu$ соседей.
\edfn

\thrm Матрица сильно $k$-регулярного графа удовлетворяет соотношению $A^2+(\mu-\lambda)A + (\mu-k)E=\mu J$, где $J$ -- это матрица из одних единиц.
\ethrm
\proof Возведём матрицу $A$ в квадрат. Тогда, число общих соседей равно числу путей длины 2 из $i$ в $j$, то есть $A^2_{ij}$. Если $i,j$ связаны между собой, то $A^2_{ij}=\lambda$, если не связаны, то $A^2_{ij}=\mu$, а на диагонали стоит $k$. Прежде всего вычтем $kE$, что даст нули на диагонали. Вычтя $\lambda A$ получим нули в тех позициях, что соответствовали рёбрам. Теперь надо добавить $\mu A+ \mu E$, чтобы эти позиции заполнить мюшками и получить $\mu J$. 
\endproof

Эта теорема позволяет легко посчитать спектры 
\crl
 Граф Петерсена сильно регулярный. Его спектр 3, 1, 1, 1, 1, 1, -2, -2, -2, -2.
\ecrl



Посмотрим, какие свойства графа можно увидеть благодаря его спектру.

\lm  След степени матрицы смежности считает количество циклов (возможно с пересечениями). В частности, граф двудольный тогда и только тогда, когда его спектр симметричен. 
\elm



Попробуем понять, какую ещё информацию даёт спектр. Воспользовавшись следствием из теоремы Куранта-Фишера получаем:

\thrm Пусть $G$ -- граф на $n$ вершинах. Пусть $A$ -- симметричная матрица $n\times n$, такая, что $A_{ij}= 0$, если вершины не соединены ребром. Пусть $n_{+}$ и $n_{-}$ количество положительных и отрицательных собственных чисел $A$. Тогда размер независимого множества в $G$ не превосходит $\min(n-n_{+},n-n_{-})$.
\ethrm
\proof Действительно, если взять подпространство, натянутое на вершины из независимого множества, то ограничение формы $x^{\top}Ax$ будет нулевым. Такое бывает только на подпространстве размерности $n-n_{+}=n_{-}+n_0$ исходя из нижней оценки. Аналогично получаем второе неравенство.
\endproof

Однако это не единственная возможная оценка. Разберём пример, использующий понятие спектра, но основанный на совершенно других предположениях.



\thrm Пусть $G$ -- $k$-регулярный граф. Тогда размер максимального независимого множества в графе оценивается как $$\alpha(G)\leq -\frac{\lambda_n}{k-\lambda_n}.$$
\ethrm
\proof Рассмотрим характеристический вектор $v$ для независимого множества размера $\alpha$. Имеем $v^{\top}Av=0$ и при этом $v^{\top}v=\alpha$. Так как граф $k$-регулярный, то у него есть нормированный собственный вектор $u_1=\frac{1}{\sqrt{n}}(1,\dots,1)$. Тогда $\lan v,u_1\ran = \frac{\alpha}{\sqrt{n}}$. Разложим вектор $v=c_1u_1 + \dots + c_n u_n$ по ортонормированной системе собственных векторов. Тогда
$$0=v^{\top}Av=\sum c_i^2 \lambda_i= \lambda_1\frac{\alpha^2}{n}+ \sum_{i\geq 2} \lambda_i c_i^2\geq \lambda_1\frac{\alpha^2}{n}+ \lambda_n \sum_{i\geq 2} c_i^2.$$
Мы знаем, что $\sum c_i^2=\alpha$, откуда $\sum_{i\geq 2} c_i^2=\alpha - \frac{\alpha^2}{n}$. Итого 
$$0\geq \lambda_1\frac{\alpha^2}{n}+\lambda_n(\alpha- \frac{\alpha^2}{n})$$
Сокращая на $\alpha$ получаем 
$$(\lambda_1-\lambda_n)\frac{\alpha}{n}\leq -\lambda_n,$$
что, очевидно, эквивалентно нужному неравенству.
\endproof

Обе оценки дают для графа Петерсена $\alpha(G)\leq 4$, что является точной оценкой. Разберём ещё один пример теоремы, которая хотя и не является сверхсодержательной, показывает, как можно использовать спектр графа.

\thrm Рассмотрим граф $K_{10}$. Тогда его невозможно покрыть тремя копиями графа Петерсона.
\ethrm

\section{Тензоры}

В прошлом семестре мы подробно остановились на билинейных операциях и их связи с геометрией, но не разобрали в достаточной степени, что же происходит с общими полилинейными отображениями.

\dfn Пусть есть набор пространств $V_1, \dots,V_n$. Тогда их тензорным произведением называется пространство 
$V_1\otimes \dots \otimes V_n$ вместе с полилинейным отображением
$$i \colon V_1 \times \dots \times V_n \to V_1 \otimes \dots \otimes V_n,$$
удовлетворяющее условию что для любого билинейного отображения из $h\colon V_1\times \dots \times V_n \to U$ существует единственное линейное отображение 
$$\hat{h}\colon V_1\otimes \dots \otimes V_n \to U,$$
что 
$$\hat{h}\circ i=h.$$
Иными словами, отображение $i$ -- это <<универсальное>> полилинейное отображение.
\edfn 


\lm Если тензорное произведение существует, то оно единственно.
\elm


Однако, совершенно непонятно есть такое пространство или нет. Более того, самом его существование нам тоже не сильно поможет. Нам нужна конструкция этого пространства и понимание свойств этой конструкции.

\thrm Пусть $V_1,\dots,V_n$ -- набор векторных пространств. Тогда имеет место следующая конструкция тензорного произведения:
$$V_1 \otimes \dots \otimes V_n \cong K\lan V_1 \times \dots \times V_n \ran / Rel,$$
где $Rel$ -- это подпространство порождённое формальными суммами
$$(\dots, \lambda v_1+v_2, \dots) - \lambda (\dots,v_1, \dots) - (\dots, v_2, \dots).$$ 
\ethrm

\dfn Будем обозначать элемент $i(v_1,\dots,v_n)=v_1\otimes \dots \otimes v_n$. 
\edfn

Теперь необходимо посчитать что-то про тензорное произведение. Например, научиться считать размерность тензорного произведения и находить его базис.
\thrm Пусть $e_{i1},\dots,e_{in}$ базис $V_i$. Тогда $e_{1j_1}\otimes \dots \otimes e_{nj_n}$ базис $V_1 \otimes \dots \otimes V_n$. В частности, 
$$\dim V_1 \otimes \dots \otimes V_n= \prod_{i=1}^n \dim V_i.$$ 
\proof Прежде всего заметим, что набор $e_{1j_1}\otimes \dots \otimes e_{nj_n}$ является порождающей системой для тензорного произведения. Далее, по определению тензорного произведения,
$$\Hom(V_1,\dots,V_n, K) \cong \Hom(V_1\otimes \dots \otimes V_n,K).$$
Размерность последнего пространства совпадает с размерностью $V_1\otimes \dots \otimes V_n$. С другой стороны, полилинейное отображение $h \in \Hom(V_1,\dots,V_n, K)$ однозначно задаётся $\prod_{i=1}^n \dim V_i$  параметрами $h(e_{1j_1}, \dots,e_{nj_n})$. Комбинируя эти два факта получаем, что размерность $\dim V_1 \otimes \dots \otimes V_n$ есть $\prod_{i=1}^n \dim V_i$. Отсюда, любая порождающая система такого размера есть базис. В частности, набор $e_{1j_1}\otimes \dots \otimes e_{nj_n}$.
\endproof
\ethrm



Определим теперь тензорное произведение линейных отображений.

\dfn Пусть набор линейных отображений $f_i \colon U_i \to V_i$. Определим отображение $$f_1\otimes \dots \otimes f_n \colon \otimes U_i \to \otimes V_i$$ по  правилу $$(f_1\otimes \dots \otimes f_n) (u_1\otimes \dots \otimes u_n) = f(u_1)\otimes \dots \otimes f(u_n).$$
Отображение с таким свойством единственно.
\edfn

\rm Указанное отображение корректно задано. Действительно,  отображение $f_1\otimes \dots \otimes f_n$ должно быть продолжением отображения $(u_1,\dots,u_n) \to f(u_1) \otimes \dots \otimes f(u_n)$, которое очевидно полилинейно. Тогда такое продолжение существует и единственно по свойству тензорного произведения. 
\erm

\rm Пусть заданы наборы линейных отображений $f_i$ и $g_i$, так что определены композиции $f_i\circ g_i$. Тогда $$f_1\otimes \dots \otimes f_n \circ g_1\otimes \dots \otimes g_n=(f_1\circ g_1)\otimes \dots \otimes (f_n\circ g_n)$$
\erm 

А как устроена матрица тензорного произведения линейных отображений?


\lm Пусть $L_1 \colon V_1 \to U_1$, а $L_2 \colon V_2 \to U_2$. Пусть $e_1,\dots, e_{n_1}$ базис $V_1$,  $e_1',\dots, e_{n_2}'$ базис $V_2$,  и $f_1,\dots, f_{m_1}$ -- базис $U_1$, а $f_1',\dots, f_{m_2}'$ -- базис $U_2$. 
Упорядочим базисы тензорных произведений -- удобно это сделать, например, в лексикографическом порядке (номер первой координаты важнее).
Тогда матрица  $L_1\otimes L_2$  разобьётся на $n_1m_1$ блоков в каждом из которых будет стоять $ A_{ij} B$, где $i,j$ -- номер блока, а $A$ и $B$ матрицы $L_1$ и $L_2$ соответственно.
\elm

\dfn Такая матрица называется кронекеровым произведением матриц $A$ и $B$ и обозначается как $A\otimes B$.
\edfn

А что если стартовать с операторов, а не с линейных отображений?

\rm Если есть операторы $A\colon V \to V$ и $B \colon W \to W$. Тогда задан оператор $A\otimes B$ на $V\otimes W$. \erm

\lm У оператора $A\otimes B$ собственные числа -- это попарные произведения с.ч. для $A$ и $B$. 
\elm


 

\dfn[Произведение графов] Пусть $G$ и $H$ -- два графа(возможно ориентированных). Тогда их категорным произведением называется граф чьи вершины есть пары вершин $G$ и $H$ и ребро между парами $(u_1,v_1)$ и $(u_2,v_2)$ проводится только если есть рёбра $u_1 \to u_2$ и $v_1 \to v_2$. Декартовым произведением графов $G$ и $H$ называется граф на тех же вершинах с ребром между парами если $u_1=u_2$ и есть ребро $v_1\to v_2$ или, симметрично, $v_1=v_2$ и есть ребро $u_1 \to u_2$. Разумеется для неориентированных графов эта конструкция снова выдаёт неориентированный граф.
\edfn

\rm Матрица произведения графов -- это тензорное произведение матриц.
\erm

\crl Спектр категорного произведения графов состоит из всех возможных попарных произведений собственных чисел графов.
\ecrl

\zd Чему равен спектр декартового произведения графов?
\ezd


С понятием тензорного произведения связан ряд канонических отождествлений между разными на первый взгляд пространствами в духе изоморфизма $V \sim V^{**}$.

\thrm Имеют место следующие естественные изоморфизмы: 
$$(U \otimes V) \otimes W \cong U \otimes V \otimes W \cong U \otimes (V \otimes W)$$
$$ U \otimes V \cong V \otimes U $$
$$ \Hom (U,V) \cong V \otimes U^*$$
$$ \Hom (U\otimes V,  W) \cong \Hom (U, \Hom (V,W))$$
$$(U \otimes V)^{*} \cong U^{*}\otimes V^{*}$$
\ethrm


Дадим определение:

\dfn Тензором валентности $(p,q)$ на пространстве $V$ называется элемент пространства ${V^{*}}^{\otimes p} \otimes V^{\otimes q}$. Так же будем говорить, что такие элементы -- это $p$ раз ковариантные и $q$ раз контравариантные тензоры. Тензорами валентности $(0,0)$ называются элементы поля $K$ -- скаляры.
\edfn

Теперь я утверждаю, что более менее все встречавшиеся нам структуры на векторном пространстве $V$ являются тензорами.



\exm\\
1) Вектор $v\in V$ является 1 раз контравариантным тензором.\\
2) Элемент двойственного пространства $f \in V^{*}$ является 1 раз ковариантным тензором. Вообще ковариантными называют тензоры, которые соответствуют полилинейным формам на пространстве $V$. Это историческая традиция. Точнее:\\
3) Так как пространство ${V^{*}}^{\otimes p} \cong \left(V^{\otimes p}\right)^*\cong \Hom(V,\dots,V,K)$, то тензор валентности $(p,0)$ соответствует полилинейному отображению $V\times\dots \times V \to K$.\\
4) В частности, тензор валентности $(2,0)$ -- это билинейная форма.\\
5) Линейный оператор -- это элемент $\Hom(V,V)\cong V^{*}\otimes V$, то есть тензор валентности $(1,1)$.\\
6) Структура алгебры на $V$ (без требования ассоциативности) задаётся билинейным отображением $V \times V \to V$, то есть линейным отображением $V\otimes V \to V$ или же элементом $V^{*}\otimes V^* \otimes V$, то есть тензором типа $(2,1)$.\\

Как записать тензор в координатах? Выберем базис $e_1,\dots,e_n$ пространства $V$ и возьмём в двойственном пространстве двойственный базис $e^1,\dots,e^n$. Теперь построим базис тензорного произведения ${V^{*}}^{\otimes p}\otimes V^{\otimes q}$. Он имеет вид $e^{j_1}\otimes\dots\otimes e^{j_p}\otimes e_{i_1}\otimes \dots \otimes e_{i_q}$. Тогда произвольный тензор $T$ валентности $(p,q)$ имеет вид 
$$ T= \sum_{\substack{i_1,\dots,i_q \in \ovl{1,n}\\ j_1,\dots,j_p \in \ovl{1,n}} } \,T_{j_1,\dots,j_p}^{i_1,\dots,i_q}\,\, e^{j_1}\otimes\dots\otimes e^{j_p}\otimes e_{i_1}\otimes \dots \otimes e_{i_q}.$$
Элементы $T_{j_1,\dots,j_p}^{i_1,\dots,i_q}$ называются координатами тензора $T$.


Как меняются координаты тензора при замене базиса? Посмотрим сначала на случай тензоров типа $(1,0)$.

\thrm Пусть $e_1,\dots,e_n$ старый базис $V$, а $\hat{e}_1,\dots,\hat{e}_n$ -- новый. Пусть $C$ -- матрица перехода из старого базиса в новый. Тогда матрица перехода из базиса $e^1,\dots,e^n$ в базис $\hat{e}^1,\dots,\hat{e}^n$ есть ${C^{\top}}^{-1}$.
\proof Зафиксируем конвенцию: матрица $C$ это такая матрица, что для всякого вектора $v$ со старыми координатами $x$ и новыми координатами $y$ выполнено, что $y=Cx$. В частности, это выполнено для вектора $e_i$. Это означает, что вектор $e_i=\sum_{j=1}^nC_{ji}\hat{e}_j$. Собственно, это ещё одна характеризация матрицы $C$. Наша задача найти матрицу $D$, со свойством $e^i=\sum D_{ji}\hat{e}^j$. По определению $e^i(e_k)=\delta_{ik}$. Подставим вместо $e^i$ и $e_k$ выражения с матрицами $C$ и $D$. Имеем
$$\delta_{ik}=\sum_{j}C_{ji} \sum_{l}D_{lk}\hat{e}^j(\hat{e}_l)=\sum_{j,l}C_{ji}D_{lk}\cdot\delta_{jl}=\sum_{j}C_{ji}D_{jk}$$
Теперь это равенство можно проинтерпретировать при помощи матричного произведения как 
$$E_n=C^{\top}D,$$
что и доказывает требуемое.
\endproof
\ethrm

Теперь мы можем разобраться с тензорами общего вида:

\thrm Пусть $e_1,\dots,e_n$ старый базис $V$, а $\hat{e}_1,\dots,\hat{e}_n$ -- новый. Пусть $C$ -- матрица перехода из старого базиса в новый, а $D={C^{\top}}^{-1}$. Тогда координаты тензора $T$ в базисе $\hat{e}$ выражаются через старые координаты следующим образом:
$$\hat{T}_{j_1,\dots,j_p}^{i_1,\dots,i_q}=\sum_{\substack{i'_1,\dots,i'_q \in \ovl{1,n}\\ j'_1,\dots,j'_p \in \ovl{1,n}}} \,\,
\prod_{t\in \ovl{1,p}} D_{j_t,j'_t} \prod_{s\in \ovl{1,q}} C_{i_s,i'_s}  \,\,T_{j'_1,\dots,j'_p}^{i'_1,\dots,i'_q}.$$
\proof Обозначим за $e^{j_1,\dots,j_p}_{i_1,\dots,i_q}$ тензор $e^{j_1}\otimes \dots \otimes e^{j_p} \otimes e_{i_1}\otimes \dots \otimes e_{i_q}$. Рассмотрим тензор
$$ T= \sum_{\substack{i'_1,\dots,i'_q \in \ovl{1,n}\\ j'_1,\dots,j'_p \in \ovl{1,n}}} T_{j'_1,\dots,j'_p}^{i'_1,\dots,i'_q} e^{j'_1,\dots,j'_p}_{i'_1,\dots,i'_q}$$ 
и заменим $e_i=\sum_{j=1}^nC_{ji}\hat{e}_j$ и $e^i=\sum D_{ji}\hat{e}^j$. Получится такая сумма:
$$ T= \sum_{\substack{i'_1,\dots,i'_q \in \ovl{1,n}\\ j'_1,\dots,j'_p \in \ovl{1,n}}} T_{j'_1,\dots,j'_p}^{i'_1,\dots,i'_q} \sum_{\substack{i_1,\dots,i_q \in \ovl{1,n}\\ j_1,\dots,j_p \in \ovl{1,n}} } D_{j_1j'_1}\dots D_{j_pj'_p} C_{i_1i'_1}\dots C_{i_qi'_q} \hat{e}^{j_1,\dots,j_p}_{i_1,\dots,i_q}$$
Осталось поменять суммирование местами.
\endproof
\ethrm

Важность тензоров в теоретической физике обуславливается тем, что практически все физические объекты -- это тензоры. Точнее: с точки зрения теории относительности пространство-время это некоторое четырёхмерное многообразие $M$ (в двумерной ситуации подошла бы обычная сфера или тор). С каждой точкой $x$ этого многообразия связано касательное пространство в этой точке -- некоторое четырёхмерное пространство $T_x$. Представим себе, что в каждой точке пространства задана плотность вещества (на самом деле не так, но допустим) -- это даёт вам функцию $f \colon M \to \mb R$ -- скаляр в каждой точке, то есть тензор типа $(0,0)$. 

Направление движения материи можно задать взяв в каждой точке касательный вектор, то есть тензор ранга $(0,1)$ на $T_x$. Дальше, у каждого такого вектора можно считать его <<длину>> и углы между векторами. Для этого надо задать для каждой точки $x$ билинейную форму на касательном пространстве, то есть элемент $T_x^{(2,0)}$. И т.д. Чаще всего такие объекты называют тензорными полями, если хочется подчеркнуть, что в разных точках это тензор вообще говоря на разных пространствах.

Важно, что уравнения в физике не должны зависеть от выбора координат. Можно, конечно, писать какие-то уравнения при помощи координат тензоров и каждый раз проверять, что выбрав новые координаты уравнение будет того же вида. Однако, чем сложнее наука тем сложнее становятся проверки. Становится важно работать с тензорами не рассматривая их координаты. Для этого мы обсудим две операции с тензорами, которые легко можно понять не используя координаты. Начнём с самой простой -- умножение тензоров.

\dfn Рассмотрим пространства $V^{p,q}$ и $V^{p',q'}$. Тогда имеет место билинейное отображение $$V^{p,q}\times V^{p',q'} \to V^{p+p',q+q'},$$
заданное правилом 
$$(v^1\otimes\dots\otimes v^p\otimes u_1\otimes\dots \otimes u_q,\hat{v}^1\otimes\dots\otimes \hat{v}^{p'}\otimes \hat{u}_1\otimes\dots \otimes \hat{u}_{q'}) \to v^1\otimes\dots\otimes v^p\otimes \hat{v}^1\otimes\dots\otimes \hat{v}^{p'}\otimes u_1\otimes\dots \otimes u_q \otimes \hat{u}_1\otimes\dots \otimes \hat{u}_{q'}.$$
Такое умножение задаёт структуру ассоциативной алгебры на пространстве 
$$T(V)=\bigoplus_{p,q\geq 0} V^{p,q},$$
которое называется тензорной алгеброй пространства $V$.
\edfn

Посмотрим теперь на пространство $V^*\otimes V$. Определим из него каноническое, то есть не зависящее от выбора базиса отображение в $K$. Действительно элементы этого пространства есть суммы тензоров вида $f\otimes v$. Сопоставим каждому такому тензору 
$$(f,v) \to f(v).$$
Такое сопоставление продолжается до линейного отображения $$Conv \colon V^*\otimes V \to K.$$
Что это за отображение в координатах? Тензор типа $(1,1)$ записывается в базисе как $T=\sum_{i,j} T_j^i e^j\otimes e_i$. Тогда $$Conv(T)=\sum_{i,j} T_j^i e^j(e_i)=\sum_i T^i_i.$$
Если вспомнить, что пространство $V^*\otimes V \cong \Hom(V,V)$, то указанное отображение становится просто отображением следа. Это ещё один способ доказать инвариантность следа. Обозначение $Conv$ взято благодаря слову <<convolution>>, то есть свёртка. Сейчас мы проделаем аналогичную конструкцию в более общем случае. 

\dfn Рассмотрим пространство $V^{p,q}$ и пару индексов $j\leq p$ и $i\leq q$. Тогда свёрткой по индексам $i,j$ называется линейное отображение 
$$Conv_{i,j} \colon V^{p,q}\to V^{p-1,q-1},$$
заданное по правилу 
$$ \dots \otimes f^j\otimes \dots \otimes v_i \otimes \dots \to f^j(v_i)\cdot f^1\otimes \dots.$$
Это одно из самых часто используемых понятий про тензоры. В координатном виде это просто сумма по совпадающим индексам в позиции $j$ и $i$. Понятно, что свёртку можно делать по одинаковым по размеру упорядоченным группам координат. Я не буду про это говорить дополнительно.
\edfn




\section{Внешняя и симметрическая алгебры}

В этом разделе мы будем рассматривать векторное пространство $V$ над полем характеристики $0$. Есть общая теория не только для полей, но и для произвольных колец, однако, даже базовые конструкции в этой теории сложнее и некоторые её утверждения просто неверны над полем ненулевой характеристики.

\dfn Определим пространство $\Lambda^k V$ как подпространство $V^{\otimes k}$. Это подпространство выделяется следующими условиями -- для любой перестановки из $\sigma \in S_k$ и любого тензора $a\in \Lambda^k V$ верно, что $a^{\sigma}=\sgn(\sigma)a$. Под $a^{\sigma}$ подразумевается действие перестановки $\sigma$ на тензор $a$ перестановкой его компонент. Аналогично определяется подпространство $\Sym^k V \leq V^{\otimes^k}$, чьи элементы удовлетворяют свойству: $a^{\sigma}=a$.
\edfn

\lm Имеет место проектор $Alt \colon V^{\otimes k} \to \Lambda^k V$ заданный формулой 
$$a \to \frac{1}{k!} \sum_{\sigma \in S_k} \sgn (\sigma) a^{\sigma}.$$
Аналогично отображение  
$$S\colon a \to \frac{1}{k!} \sum_{\sigma \in S_k} a^{\sigma}$$
есть проектор на подпространство $\Sym^k V$.
\elm

\dfn Пусть $e_1,\dots, e_k$ набор элементов из $V$. Определим элементы $e_1\wedge \dots \wedge e_k \in \Lambda^k V$ как образы при проекции $e_1\otimes \dots \otimes e_k$.
\edfn

\thrm Пусть $e_1,\dots, e_n$ базис пространства $V$. Тогда элементы $e_{i_1}\wedge \dots \wedge e_{i_k}$, где $i_1<i_2< \dots < i_k$ образуют базис пространства $\Lambda^k V$. В частности размерность $\dim \Lambda^k V = C^k_n$.
\ethrm

\thrm Аналогично, пусть $e_1,\dots, e_n$ базис пространства $V$. Тогда элементы образы тензоров $e_{i_1}\otimes \dots \otimes e_{i_k}$, где $i_1\leq \dots \leq i_k$ образуют базис пространства $\Sym^k V$.
\ethrm

\dfn Определим $k$-ую внешнюю степень линейного отображения $L\colon V \to W$ -- отображение $\Lambda^{k} L  \colon \Lambda^k V \to \Lambda^k W$ заданное на тензорах по правилу $v_1\wedge \dots \wedge v_k \to L v_1 \wedge \dots \wedge L v_k$. 
\edfn

Для того, чтобы показать корректность такого определения покажем следующую теорему:

\thrm Рассмотрим отображение $g=Alt \circ i \colon V^{\times k} \to \Lambda^k(V)$. Тогда для любого полилинейного кососимметрического $h \colon V^{\times k} \to U$ существует единственное отображение $\hat{h} \colon \Lambda^k(V) \to U$, что $\hat{h} \circ g = h$.
\ethrm


\fct Полезно смотреть не на пространства $\Lambda^k (V)$ и $\Sym^k V$, а на пространства $\Lambda^k(V^*)$ и $\Sym^k(V^*)$, потому что они допускают привычную и наглядную интерпретацию --- их элементы это полилинейные функции со специальными свойствами.
\efct


\exm \\
1) Элемент $\Lambda^2(V^*)$ --- это просто кососимметрическая билинейная форма.\\
2) А элемент $\Sym^2 V^*$ -- это симметрическая билинейная форма или просто квадратичная форма.\\
3) Элемент $\Lambda^{\dim V} V^*$ -- это просто форма объёма на $V$.\\
4) Заметим, что продолжая аналогию с квадратичными формами, выбор базиса задаёт изоморфизм 
$$\Sym^k V^* \cong K[x_1,\dots, x_n]_{\deg =k}$$
с пространством однородных многочленов степени $k$ ($n$ -- размерность пространства). Последнее отображение устроено следующим образом -- элементу $a \in \Sym^k V^* $ сопоставим отображение, которое на векторе $v=x_1e_1+\dots+x_ne_n $ выдаёт $a(v,\dots,v)$. То есть 
$$a \to (v \to a(v,\dots,v)).$$
 Это будет однородный многочлен от координатных функций $x_1, \dots, x_n$. Осталось заметить, что проекция тензора $e^{i_1}\otimes \dots \otimes e^{i_k}$ после применения такой операции --- это многочлен $x_{i_1}\dots x_{i_k}$.
 
По аналогии с тензорной алгеброй мы хотим ввести умножение на кососимметричных тензорах. Есть два подхода: первый из них -- потребовать, чтобы пара $v_1 \wedge \dots \wedge v_p , u_1\wedge \dots \wedge u_q$ переходила в $v_1 \wedge \dots \wedge v_p \wedge u_1\wedge \dots \wedge u_q$. С таким подходом возникает вопрос о корректности. С другой стороны, такое умножение удобно вычислять. Второй подход -- связать это умножение с обычным умножением тензоров. Проблема возникает в следующем -- если $T_1$ и $T_2$ -- кососимметрические тензоры, то $T_1\otimes T_2$ вообще говоря не кососимметрический. Вот как мы с этим разберёмся

\thrm[Внешняя алгебра] Рассмотрим пространства $\Lambda(V)=\oplus_{k=0}^{\dim V} \Lambda^k(V)$ и введём на нём структуру ассоциативной алгебры по правилу $ f\wedge g= Alt(f\otimes g)$. Если $f\in \Lambda^p(V)$, а $g \in \Lambda^q(V)$, то $f\wedge g=(-1)^{pq}g \wedge f$. Такое свойство называется градуированной коммутативностью. Более того, пара $v_1 \wedge \dots \wedge v_p , u_1\wedge \dots \wedge u_q$ переходит при этом умножении в $v_1 \wedge \dots \wedge v_p \wedge u_1\wedge \dots \wedge u_q$. Такое умножение называется внешним произведением тензоров.
\proof Для этого удобно проверить тождество $Alt(Alt(T_1)\otimes T_2)= Alt(T_1\otimes T_2)= Alt(T_1 \otimes Alt(T_2))$, которое говорит, что внутри альтернирования можно свободно альтернировать сомножители не боясь ничего поменять. Действительно
$$\frac{1}{k!}\sum_{\sigma \in S_{k}}\sgn(\sigma) Alt(T_1^{\sigma}\otimes T_2)=\frac{1}{k!}\sum_{\sigma \in S_{k}} \sgn^2(\sigma) Alt(T_1\otimes T_2)=Alt(T_1 \otimes T_2).$$
Аналогично получается второе равенство. Теперь видно, что 
$$Alt(v_1 \wedge \dots \wedge v_p \otimes u_1\wedge \dots \wedge u_q)=Alt(v_1 \otimes \dots \otimes v_p \otimes u_1\wedge \dots \wedge u_q)=Alt( v_1 \otimes \dots \otimes v_p \otimes u_1\otimes \dots \otimes u_q) =v_1 \wedge \dots \wedge v_p  \wedge u_1\wedge \dots \wedge u_q .$$
Это показывает связь нашего определения умножения с ожидаемым определением. Ассоциативность теперь легко проверить на базисных элементах, как и градуированную коммутативность.
\endproof
\ethrm

Изначально, внешняя алгебра была нужна для <<исчисления подпространств>> в пространстве $V$. А именно, подпространству $U\leq V$ размерности $k$ можно сопоставить прямую $\Lambda^k U$ в $\Lambda^k V$. Более того, задав на $U$ форму объёма можно выбрать на этой прямой определённую точку. Такие объекты теперь можно перемножать и складывать, хотя в общем случае может получиться и объект, не соответствующий никакому подпространству. 

Сейчас понятие внешней алгебры служить удобным формализмом для определения интегрирования. А именно по многообразию размерности $n$ можно проинтегрировать кососимметричное тензорное поле валентности $(n,0)$, то есть заданную в каждой точке многообразия форму объёма на касательном пространстве. В общем же виде тензорные поля типа $(p,0)$ называются дифференциальными формами порядка $k$. На таких дифференциальных формах задана операция взятия дифференциала, делающая из $k$-формы $k+1$-форму. Это ещё одна из канонических <<бескоординатных>> операций. Об этом вам расскажут в курсе анализа.

\thrm[Симметрическая алгебра] Рассмотрим пространство $\Sym(V)=\oplus_k \Sym^k(V)$. Тогда на нём можно ввести структуру ассоциативной коммутативной алгебры задав умножение как $ f*g= S(f\otimes g)$. Более того, указанная алгебра изоморфна алгебре многочленов.
\proof Очевидно, что операция билинейна. Осталось проверить ассоциативность, для чего можно ограничиться рассмотрением базисных элементов. Это будет полезно в дальнейшем. Найдём непосредственно произведение $e_{i_1}\dots e_{i_k}\cdot e_{j_1}\dots e_{j_l}$. Я утверждаю, что оно равно $e_{i_1}\dots e_{i_k} e_{j_1}\dots e_{j_l}$.
Для этого удобно проверить тождество $S(S(T_1)\otimes T_2)= S(T_1\otimes T_2)= S(T_1 \otimes S(T_2))$, которое говорить, что внутри симметризации можно свободно симметризовать сомножители не боясь ничего поменять. Действительно
$$\frac{1}{k!}\sum_{\sigma \in S_{k}} S(T_1^{\sigma}\otimes T_2)=\frac{1}{k!}\sum_{\sigma \in S_{k}} S(T_1\otimes T_2)=S(T_1 \otimes T_2).$$
Аналогично получается второе равенство.
Теперь $e_{i_1}\dots e_{i_k}\cdot e_{j_1}\dots e_{j_l}= S(e_{i_1}\otimes\dots \otimes e_{i_k}\otimes e_{j_1}\otimes \dots\otimes e_{j_l})=$
Очевидно, что умножение заданное таким правилом ассоциативно. Коммутитивно оно по свойству симметрической степени. На самом деле, сопоставляя тензору $e_{i_1}\dots e_{i_k}$ моном $x_{i_1}\dots x_{i_k}$ мы строим изоморфизм алгебры $\Sym V$ и $K[x_1,\dots,x_{\dim V}]$.
\endproof
\ethrm




Покажем способ применения внешней степени для доказательства тождеств про определители. Прежде всего пусть есть отображение $L \colon U \to V$, где $\dim U= \dim V = n$ и $A$ матрица $L$ в базисах $e_1,\dots e_n$ и $f_1,\dots,f_n$. Тогда $$\Lambda^n L(e_1\wedge \dots \wedge e_n) = \det A \,\,f_1 \wedge \dots \wedge f_n.$$
Из этого замечания уже легко получить мультипликативность определителя. Поступая аналогично можно доказать более общую теорему:
 
\thrm[Формула Бине-Коши] Рассмотрим две матрицы $A\in M_{m\times n}(K)$ и $B\in M_{n\times m}(K)$. Пусть $m\leq n$. Тогда
$$\det(AB)=\sum_{\substack{\Gamma \subseteq \{1,\dots,n\}\\ |\Gamma|=m}} \det A^{\Gamma} \det B_{\Gamma}.$$
\ethrm







\chapter{Многочлены}
Настала пора вернуться к кольцу многочленов. Но на этот раз мы поговорим подробно о кольце многочленов от $n$ переменных. Мы знаем, что кольцо многочленов $K[x]$ над полем $K$ является областью главных идеалов. Есть ли надежда сказать тоже самое про многочлены от двух переменных? 

Ответ на этот вопрос даёт следующий пример: рассмотрим идеал $\lan x,y \ran$ в кольце $K[x,y]$. Это максимальный идеал. Но как мы знаем, этот идеал нельзя породить одним элементом (см. отступление про модули в прошлом семестре). 

Однако мы интуитивно представляем то, что разложение многочленов на множители однозначно. Напомню, что математически такое свойство называлось факториальностью. Итак, наша ближайшая цель поговорить о факториальности колец многочленов. Однако, для приложений к теории чисел нам будет необходимо разработать теорию в достаточной общности, чтобы применить её и над $\mb Z$, а не только над полем. Заметим, что $\mb Z$ и поле $K$ являются факториальными кольцами. Мы покажем, что факториальность кольца влечёт факториальность кольца многочленов над ним, что полностью ответит на наши вопросы.



\section{Многочлены над факториальным кольцом}

Наша задача обсудить, что происходит с кольцом многочленов от многих переменных.


\lm[Гаусс] Пусть $R$ -- факториальное кольцо. Тогда любой простой элемент $p$ из $R$ остаётся простым в $R[x]$.
\proof
Теоретически удобно воспользоваться следующим соображением: чтобы показать, что элемент прост надо показать, что идеал $(p)$ в $R[x]$ прост, а для этого необходимо и достаточно установить, что $R[x]/(p)$ есть область целостности. Чему же равно $R[x]/(p)$? Я утверждаю, что оно равно $R/p[x]$. Действительно, из $R[x]$ есть отображение в $R/(p)[x]$, которое берёт все коэффициенты по модулю $p$. Очевидно, в его ядре лежат многочлены, все коэффициенты которых делятся на $p$, то есть многочлены кратные $p$ в $R[x]$. Но ровно они и образуют идеал $(p)$. Осталось заметить, что кольцо $R/p$ и вслед за ним кольцо $R/p[x]$ являются областями целостности.

У этого доказательства есть другая, более элементарная реинкарнация. А именно, формально нам надо доказать, что если произведение двух многочленов $f(x)g(x)$ делится на $p$ (то есть все коэффициенты кратны $p$), то тогда какой-то из них делится на $p$. Пусть это не так. Возьмём тогда у $f$ и у $g$ самые младшие коэффициенты $a_i$ и  $b_j$, которые не делятся на $p$. Тогда посмотрим на коэффициент с номером $i+j$  в произведении. Он имеет вид $c_{i+j}= a_ib_j + \sum_{k \neq i} a_k b_{i+j -k}$. Я утверждаю, что $c_{i+j}$ не делится на $p$. Для этого заметим, что любое слагаемое в сумме делится на $p$, так как либо $k<i$ и тогда $a_i \di p$, либо $k>i$, то есть $i+j-k<j$ и следовательно $b_j \di p$. Противоречие с тем, что $c_{i+j}$ должен делиться на $p$.   
\endproof
\elm

\bupr Поясните, почему оба доказательства одинаковы.
\eupr

\dfn Пусть $f(x)$ -- многочлен над факториальным кольцом $R$. Тогда содержанием $f$ называется $\cnt(f)=\Nod (a_i)$, где $a_i$ коэффициенты $f$. 
\edfn

Тут есть некоторая вольность -- надо помнить, что наибольший общий делитель определём с точностью до обратимых множителей. Следующее следствие тоже называют леммой Гаусса.

\crl Если $f(x)=g(x)h(x)$, где $f,g,h \in R[x]$, то $\cnt(f)=\cnt(g)\cnt(h)$
\proof Для начала, упростим задачу, то есть сведём задачу к случаю $\cnt g= \cnt h =1$. Для этого надо рассмотреть многочлены $\frac{g}{\cnt g}$ и $\frac{h}{\cnt h}$. Их произведение есть $\frac{f}{\cnt{g}\cnt{h}}$ имеет содержание $\frac{\cnt f}{\cnt g \cnt h}$ и если показать его единичность, то мы добьёмся требуемого. Итак считаем, что $\cnt g= \cnt h=1$. Если $\cnt f$ не обратим, то $\cnt f \di p$, где $p$ простой элемент из $R$. Но тогда один из $g$ или $h$ делится на $p$ благодаря его простоте. 
\endproof
\ecrl



\lm Пусть для многочлена $f(x) \in R[x]$  имеет место разложение $f(x)=g(x)h(x)$, где  $g(x)h(x) \in Q(R)[x]$. Тогда существуют такая константа $c \in Q(R)$, что $cg \in R[x]$ и $c^{-1}h \in R[x]$, что означает, что $f(x)=cg(x)c^{-1}h(x)$ -- есть произведение двух многочленов из $R[x]$ пропорциональных исходным.
\proof
Рассмотрим несократимую запись для коэффициентов $g$ и $h$ и обозначим наибольший общий делитель их знаменателей за $d_1$ и $d_2$ соответственно. Тогда $d_1g$ и $d_2h$ лежат в $R[x]$. Имеет место равенство $d_1 d_2\cnt f = \cnt(d_1 g) \cnt(d_2h)$. Таким образом, правая часть делится на $d_1d_2$. На самом деле $\cnt(d_1 g) \di d_2$ так как $d_2$ и $\cnt(d_2h)$ взаимно просты. Аналогично $\cnt(d_2h) \di d_1$. Осталось взять в качестве $c= \frac{d_1}{d_2}$.

\endproof
\elm


\thrm Пусть $R$ -- факториальное кольцо. Тогда кольцо $R[x]$ факториально. Более того, имеет место следующее описание простых элементов кольца $R[x]$:\\
1)  $\cnt(f)=1$ и $f$ неприводим в $Q(R)[x]$.\\
2) $f=p \in R$ -- простой в $R$.
\proof 
Для начала покажем, что все указанные ситуации приводят к простым элементам в кольце $R[x]$ и что других простых и, более того, неприводимых не бывает.
Итак, пусть $f \in R[x]$ неприводим в $Q(R)[x]$. Если $gh\di f$, то это же верно над $Q(R)$ и, можно считать например, что $g\di f$ в $Q(R)[x]$. Тогда $g= fk$. Теперь можно домножить на подходящую константу $g= (cf) (c^{-1}k)$ чтобы получить равенство в $R[x]$. Заметим, что $c(c^{-1}k)$ из $R[x]$, что показывает, что $g \di f$ в $R[x]$. Второй случай полностью следует из леммы Гаусса.


Теперь покажем, что любой элемент раскладывается в произведение указанных простых. Для этого сначала разложим $f$ в $Q(R)[x]$ в произведение неприводимых $f=\prod g_i$, $g_i \in Q(R)[x]$. Далее сделаем из $g_i$ элементы $\hat{g}_i$ из $R[x]$ с $cont(g_i)=1$, что $f=a\prod \hat{g}_i$. Заметим, что $a=cont(f)$ и, следовательно, лежит в $R$. Итого $f=a\prod \hat{g}_i$, где $ 0 \neq c \in R$. Осталось разложить $c$.

Осталось показать единственность. Это следует лишь из того, что у нас есть разложение на простые. Действительно, если $f=\prod p_i=\prod q_i$, то $p_i \di \prod q_i$ и благодаря простоте делит скажем $q_i$. Но тогда $p_ih=q_i$, откуда, благодаря неприводимости $q_i$ получаем, что $h$ обратим, то есть, что $p_i \sim q_i$. Тогда можно сократить на $p_i$ и продолжить по индукции. Отсутствие простых отличного от указанных типов следует теперь из единственности разложения.
\endproof
\ethrm





\section{Признаки неприводимости для многочленов}

Теперь наша задача поговорить про неприводимость многочленов над целыми числами или над $\mb Q$. 
Прежде всего отметим, что обе задачи тесно связаны. А именно, если взять многочлен с рациональными коэффициентами, то домножив его на подходящую рациональную константу мы получим многочлен с целыми коэффициентами и содержанием 1, который по доказанному ранее неприводим тогда и только тогда, когда неприводим исходный. Обратно, неприводимость целочисленных многочленов интересна только в случае, когда содержание этих многочленов равно единице. А в этом случае это эквивалентно рациональной неприводимости. Однако все теоремы я буду формулировать в общем контексте.



\thrm[Редукционный критерий] Пусть $R$ факториальное кольцо, $f \in  R[x]$ многочлен, а $p$ -- простой элемент. Тогда, если старший коэффициент $f$ не делится на $p$ и $\ovl{f}$ неприводим в кольце $R/p[x]$, то он неприводим над $Q(R)$. 
\proof Прежде всего перейдём от многочлена $f$ к $\frac{f}{cont(f)}$ с содержанием равным 1. Достаточно доказать неприводимость  последнего над $Q(R)$, которая эквивалентна его неприводимости над $R$. Итак пусть $cont(f)=1$ и пусть $f=gh$, где $g,h$ --  не константы. Старшие коэффициенты $g$ и $h$ тоже не делятся на $p$. Имеем $\ovl{f}= \ovl{g}\ovl{h}$ и $\deg g = \deg \ovl{g}$ и $\deg h = \deg \ovl{h}$, что даёт нетривиальное разложение $\ovl{f}$ и приводит к противоречию.
\endproof
\ethrm

Вот примеры о том, как пользоваться этим критерием и что не надо забывать про условие со старшим коэффициентом. 


\exm\\
1) Многочлен $x^3+x+1$ неприводим над $\mb F_2=\mb Z/2$, потому что у него нет корней. Следовательно многочлены $3x^3+8x^2+5x+7$ и скажем, $5x^3-4x^2+x+15$ неприводимы над $\mb Q$.\\
2) Рассмотрим многочлен $px^2+x$. Он приводим, но по модулю $p$ -- неприводим.\\
3) Критерий из теоремы сформулирован не в самом сильном виде. А именно, представим себе, например, что по модулю 2 многочлен степени пять разложился в произведение двух неприводимых степени 2 и 3, а по модулю 3 -- в виде произведения степени 4 и 1. Ясно, что он неприводим.\\
4) Не стоит забывать, что если многочлен неприводим над $\mb R$, то он так же неприводим над $\mb Q$. Это, правда, очень слабый критерий, но в комбинации с пунктом 3) может что-то дать.\\



Есть, однако, такие многочлены, которые неприводимы, но раскладываются по модулю любого простого. Например, $$x^4+1=(x-e^{\frac{i\pi}{8}})(x-e^{\frac{3i\pi}{8}})(x-e^{\frac{5i\pi}{8}})(x-e^{\frac{7i\pi}{8}})= (x^2+i)(x^2-i)=(x^2+\sqrt{2}x+1)(x^2-\sqrt{2}x+1)=(x^{2}+\sqrt{-2}x+1)(x^{2}-\sqrt{-2}x+1).$$ Он не имеет корней, а любые множители степени 2 имеют нерациональный коэффициент.

С другой стороны по любому простому модулю либо из $-1$, либо из $2$ либо из $-2$ извлекается корень.

Покажем теперь некоторый критерий неприводимости, который применим в случае, если разложение по модулю $p$ получилось неудачное. А именно, представим себе, что $f(x) \equiv x^{n} \mod p$. То есть развалился в произведение максимально возможного числа одинаковых множителей. Оказывается, что в этом случае неприводимость многочлена $f$ зависит от его класса по модулю $p^2$. Точнее:

\thrm[Признак Эйзенштейна] Пусть $R$ -- факториальное кольцо и $f(x)= a_0 + \dots + a_n x^n$. Если $a_n \ndi p$, все $a_i \di p$ $i<n$, но $a_0\ndi p^2$, то многочлен $f(x)$ неприводим.
\proof
Предположим, что $f=gh$. Заметим, что старшие коэффициенты $b_k$ и $c_l$ у $g$ и $h$ не делятся на $p$. Пусть так же $b_0 \ndi p$ у многочлена $g$. Рассмотрим самый младший коэффициент у $h$ не делящийся на $p$. Такой есть, потому что $c_l\ndi p$ и это точно не $c_0$. Пусть это $c_s$. Тогда $a_s=c_sb_0+c_{s-1}b_1+\dots+c_0b_s$. Все слагаемые, кроме первого делятся на $p$. Но тогда $a_s \ndi p$, что невозможно.
\endproof
\ethrm 


Всё, что мы пока обсуждали не говорит ничего о том, как же разложить многочлен на неприводимые множители. Первое, что мы обсудим -- вопрос, почему эта задача в принципе разрешима.

Итак, пусть есть целочисленный многочлен $f(x)$ и мы хотим разложить его на множители. Мы будем искать разложение на целочисленные многочлены, заметим, что хотя бы один из них имеет степень меньшую, чем $[\frac{n}{2}]$. Вспомним о задаче интерполяции. Если $g$ -- искомый делитель $f$, то $g$ определяется своими значениями в $[\frac{n}{2}]+1$ точке, например в точках $0,1,\dots, [\frac{n}{2}]$. Более того, $f(i) \di g(i)$. Таким образом набор $g(0),\dots, g([\frac{n}{2}])$ состоит из делителей $f(0),\dots,f([\frac{n}{2}])$. Найти все такие наборы -- конечный перебор. По каждому набору многочлен $g$ восстанавливается однозначно.

Это очень неэффективный алгоритм разложения многочлена на множители. Он был предложен Кронекером ещё в 19-ом веке. В настоящее время известен полиномиальный алгоритм решения этой задачи. 

Прежде чем продвинуться дальше в исследовании разложения многочленов от одной переменной на множители стоит немного поговорить о задаче разложения многочленов от нескольких переменных. Сейчас мы увидим ещё один не трюк от Кронекера, который позволит свести эту задачу к предыдущей.

\thrm Пусть $R$ -- кольцо. Тогда различным разложениям $f(x_1,\dots,x_n)\in R[x_1,\dots,x_n]$   соответствуют различные разложения $\hat{f}=f(x, x^d, x^{d^2}, \dots, x^{d^{n-1}})$ для $d$ больших $\max_{i=1}^n \{\deg_{x_i} f\}$.
\proof Пусть $f=g_1h_1=g_2h_2$ и пусть $g_1\neq g_2$. Покажем, что $\hat{g_1}\neq \hat{g_2}$. Для этого посмотрим что происходит с мономом $x^{\alpha}$ при указанном преобразовании. Он переходит в многочлен $x^{\alpha_1+\alpha_2d+\dots+\alpha_n d^{n-1}}$. По условию все $\alpha_i<d$ как степени при переменных $x_i$. Тогда моном $x^{\alpha_1+\alpha_2d+\dots+\alpha_n d^{n-1}}$ может быть получен только из монома $x^{\alpha}$. Заметим теперь, что $\deg_{x_i} g_j \leq \deg f <d$. Следовательно мономы многочленов $g_j(x)$ так же однозначно восстанавливаются по мономам $\hat{g_j}$.
\endproof
\ethrm

К сожалению, не стоит ожидать взаимооднозначного соответствия между разложениями многочленов $f$ и $\hat{f}$. Например, многочлен $x_2^2$ раскладывается на два множителя одним способом. При $d=3$ его образ есть $x^6$ у которого 3 различных разложений.

Теперь вернёмся к многочленам от одной переменной. Для проверки неприводимости мы с успехом использовали информацию, полученную из разложения по модулю $n$. Вопрос -- нельзя ли её же использовать и в целочисленной задаче? 

Во-первых, если взять достаточно большой модуль $n$, заметно больший, чем коэффициенты в целочисленном разложении, то разложение $f$ по модулю $n$ с маленькими коэффициентами однозначно будет определять кандидата на целочисленное разложение. Это соображение встречается сразу с двумя проблемами -- первая -- не ясно какие есть ограничения на коэффициенты сомножителей, вторая -- разложений по модулю $n$ может быть много и нет способа эффективно искать их.



Как же теперь выбрать достаточно большое число, по модулю которого раскладывать многочлен $f$ на множители? В первую очередь, должно быть удобно раскладывать многочлен по подходящему множителю. Наибольшим удобством в решении задачи разложения обладают поля. В этом смысле возможно стоило бы искать разложение $f$ по модулю очень большого простого. Однако найти большое простое число довольно тяжело. Смотреть по модулю маленьких простых а потом пытаться склеивать разложение в духе китайской теоремы об остатках может банально не получиться (как в примере 3 -- неясно во что склеить два разных разложения). Оказывается наиболее оптимальный вариант такой -- взять небольшое простое число $p$, разложить $f$ над $\mb Z/p$ а затем <<поднять>> это разложение по модулю $p^k$ для достаточно большого $k$. Сформулируем утверждение, которое пояснит как это сделать.

\lm[Гензеля] Пусть $f \in \mb Z[x]$, со старшим коэффициентом не делящимся на простое число $p$. Пусть $\ovl{f}=gh$ в кольце $\mb Z/p[x]$, причём $(g,h)=1$. Тогда  для любого $k\geq 1$ существуют единственные многочлены $\hat{g}, \hat{h} \in \mb Z[x]$, что $\ovl{f}=\hat{g} \hat{h} \mod p^k$  и $\deg h= \deg \hat{h}$, $\deg g= \deg \hat{g}$, $\hat{g}\equiv g (\mod p)$, а $\hat{h}\equiv h (\mod p)$.
\proof Докажем это индукцией по $k$. 
\endproof
\elm


Частным случаем разложения на множители служит разложение вида $f(x)=(x-x_1)g(x)$, соответствующее наличию корня. Сформулируем следствие леммы Гензеля в этой ситуации:


\crl Пусть $f \in \mb Z[x]$, со старшим коэффициентом не делящимся на простое число $p$. Пусть $a$ корень $f$ по модулю $p$, причём $\ovl{f}'(a)\neq 0$. Тогда  для любого $k\geq 1$ существует единственный $ \hat{a}\in \mb Z/p^k$,  что $f(\hat{a})=0$ и $\hat{a} \equiv a \mod p$.
\proof
\endproof
\ecrl

\rm Можно усилить лемму Гензеля, рассматривая подъём разложения не с модуля $p$, а с модуля $p^k$ заработав ослабление условия на производную.
\erm


Теперь алгоритм разложения на множители уже вырисовывается. Но в лемме Гензеля есть некоторые ограничения на разложение многочлена $\ovl{f}$. Как с этим жить мы узнаем дальше.




   









\section{Симметрические многочлены}

Мы стартовали с задачи нахождения уравнения для элемента из $\beta \in K[\alpha_1, \dots, \alpha_n]$, где $\alpha_1,\dots, \alpha_n$ --- все корни некоторого многочлена $p(x)\in K[x]$. 

Оказалось, что формулу довольно легко написать. А именно, если $\beta=f(\alpha_1, \dots, \alpha_n)$, где $f\in K[x_1,\dots,x_n]$ --- многочлен, то подойдёт
 $$g(x)=\prod_{\tau \in S_n} (x - f(\alpha_{\tau(1)}, \dots, \alpha_{\tau(n)})).$$

Действительно, ясно, что $\beta$ есть корень этого многочлена. Вопрос --- почему его коэффициенты из $K$? Ответ: потому что они есть симметрические функции (над $K$) от корней многочлена $p(x)$ и, следовательно, полиномиально (над $K$) выражаются через коэффициенты $p(x)$. 

\begin{defn}
Функция $\sigma_k(x_1,\dots, x_n)= \sum_{1\leq i_1<\dots<i_k\leq n}x_{i_1}\dots x_{i_k}$ называется элементарной однородной степени $k$ симметрической функцией от переменных $x_1,\dots, x_n$. Если многочлен $p(x)=(x-x_1)\dots(x-x_n)=x^n+a_{n-1}x^{n-1}+\dots+a_0$, то $a_i=(-1)^{n-i}\sigma_{n-i}(x_1,\dots, x_n)$.
\end{defn}

\begin{thm} Пусть $f(x_1,\dots, x_n)$ --- симметрический многочлен из $R[x_1,\dots, x_n]$ ($R$ можно взять произвольным коммутативным кольцом, нас в основном будет интересовать случай, когда $R$ --- поле или кольцо $\mb Z$). Тогда существует единственный многочлен $g(y_1, \dots, y_n)\in R[y_1,\dots, y_n]$, что  $$g(\sigma_1, \dots, \sigma_n)=f(x_1, \dots, x_n).$$
\end{thm}
\proof
Совершенно понятно, что теорему можно доказывать по отдельности для однородных многочленов фиксированной степени $l$. Теперь необходимо ввести упорядочивание на мономах. Если многочлен однородный степени $l$, то любой моном, который входит в его представление имеет вид $x_1^{\lambda_1}\dots x_n^{\lambda_n}$ где $\sum \lambda_i = l$. Как обычно будем обозначать за $\lambda$ набор из степеней $(\lambda_1,\dots,\lambda_n)$, а соответствующий моном за $x^{\lambda}$. Видно, что мономы соответствуют упорядоченным разбиениям числа $l$ на слагаемые. Будем говорить, что два разбиения $\lambda>\mu$, если $\lambda_1=\mu_1,\dots, \lambda_s=\mu_s, \lambda_{s+1}>\mu_{s+1}$.

Теперь будем убирать из $f$ самые большие мономы. Если старший моном соответствовал разбиению $\lambda=(\lambda_1,\dots,\lambda_n)$, то $\lambda_i\geq \lambda_{i+1}$ (из-за симметричности $f$). Тогда из $f$ надо вычесть 
$$\sigma_1^{\lambda_1-\lambda_2}\dots \sigma_{n-1}^{\lambda_{n-1}-\lambda_n}\sigma_n^{\lambda_n}$$
с подходящим коэффициентом. И т.д. Покажем единственность. Пусть есть многочлен 
$g(y_1,\dots,y_n),$ такой что $$g(\sigma_1,\dots,\sigma_n)=0.$$
На мономах многочлена $g$ рассмотрим следующий порядок: по мультииндексу $\alpha$ построим мультииндекс $\lambda$ по правилу $\lambda_i=\sum_{j\geq i} \alpha_i$, и сравним $\lambda$ лексикографически. Заметим, что $\lambda$ -- это мультииндекс соответствующий старшему моному в $y^{\alpha}(\sigma_1,\dots,\sigma_n)$. 
 
Рассмотрим наибольший моном $y^{\alpha}$ в $g(y_1,\dots,y_n)$ относительно этого порядка. Тогда у $g(\sigma_1,\dots,\sigma_n)$ моном $x^{\lambda}$ не сократится.
\endproof




\begin{rem}
Функция $g(x)=\prod_{\tau \in S_n} (x - f(\alpha_{\tau(1)}, \dots, \alpha_{\tau(n)}))$ хороша всем, кроме того, что её степень $n!$. Если многочлен $f$ специального вида, то можно обойтись функцией меньшей степени. Например, если $f(x_1, \dots, x_n)=x_1^s$, то достаточно взять $g(x)=\prod_{i=1}^n (x - x_i^s)$.
\end{rem}



Отдельно стоит вопрос, какие ещё симметрические функции, (кроме элементарных) задают значения всех остальных симметрических функций? 

\dfn Новым важным примером симметрических многочленов являются суммы степеней 
$$s_k(x_1, \dots, x_n)=x_1^k+\dots+x_n^k$$
\edfn

Для этих функций справедливы тождества Ньютона, которые связывают их с элементарными симметрическими:

\lm[Тождества Ньютона] Степенные суммы и элементарные симметрические многочлены связаны тождествами
$$0=(-1)^n n\sigma_n + \sum_{k=0}^{n-1}(-1)^k \sigma_k s_{n-k}$$
\proof Рассмотрим равенство $$(x-x_1)\dots(x-x_n)=x^n+\sum (-1)^{n-i}\sigma_{n-i} x^i.$$ 
Подставим в это равенство $x=x_j$. Получим $$0=x_j^n+\sum (-1)^{n-i}\sigma_{n-i} x_j^i.$$
Просуммируем по всем $j$. Получим 
$$0=s_n+\sum_{i\neq 0} (-1)^{n-i}\sigma_{n-i} s_i + (-1)^nn\sigma_n$$
Это доказывает равенство, когда число переменных равно номеру $\sigma_n$. Подставив переменные $x_{k+1},\dots, x_n$ равные 0 в это равенство получим его для $k$ переменных $k<n$. 

Теперь  предположим, что $k>n$. Проверим, что справа и слева однинаковые мономы входят с одинаковым коэффициентом.

Заметим, что в каждом мономе заведомо участвует не более $n$ различных переменных так степень каждого монома ровно $n$. Пусть мы хотим проверить наличие справа и слева одинакового числа мономов в записи которых участвуют  переменные $x_{i_1},\dots, x_{i_n}$. Подставим вместо всех остальных переменных 0. Понятно, что с искомым мономом ничего не произойдёт. С другой стороны после такой подстановки и переобозначения переменных мы приходим к уже доказанному равенству, когда $k=n$.
\endproof
\proof Вот другое доказательство. Рассмотрим произведение
 $$ \Sigma(t)=\prod_{i=1}^n (1-x_it)=\sum_{i=0}^n (-1)^i \sigma_i t^i.$$
Это производящая функция для $(-1)^i\sigma_i$. Производящую функцию для $s_i$ можно записать в следующем виде:
$$S(t)=\sum_{i=1}^{\infty} s_i t^i= \sum_{i=1}^n \frac{x_it}{1-x_it}.$$
Свяжем первую и вторую функции -- рассмотрим 
$$t \frac{d}{dt} \Sigma(t)=\sum_{i=1}^n (-1)^i i\sigma_i t^i = \sum_{j=1}^n -x_jt \prod_{i\neq j}^n (1-x_it)=\left(\prod_{i=1}^n (1-x_it)\right)\left(\sum_{j=1}^n \frac{-x_jt}{1-x_jt}\right)=-S(t) \Sigma(t).$$
Осталось раскрыть скобки.
\endproof
\elm



\begin{comment}

Кроме сумм степеней встречаются так же  полные однородные симметрические многочлены степени $k$. 

\dfn Полным однородным симметрическим многочленом от переменных $x_1,\dots,x_n$ степени $k$ называется
$$p_k(x_1,\dots, x_n)= \sum_{\substack{\lambda_1+\dots+\lambda_n=k \\ \text{различные разбиения}} } x_1^{\lambda_1}\dots x_n^{\lambda_n}.$$
\edfn

Мы про них ничего не говорили. Они -- альтернатива элементарным симметрическим -- все другие так же выражаются через них. Для них есть тождества типа тождеств Ньютона, связывающие их со степенными суммами.



Важный пример симметрических многочленов --- мономиальные функции. Их много. Они хороши тем, что образуют базис пространства всех симметрических многочленов (в отличие от элементарных, степенных, полных однородных).

\dfn Пусть $\lambda_1\geq \lambda_2\geq \dots \geq \lambda_n$ --- разбиение числа $n$ на слагаемые.
$$m_{\lambda}=\sum_{\substack{\text{по неповторяющимся}\\ \text{мономам}}} x^{\lambda_1}_{\tau(1)}\dots x^{\lambda_n}_{\tau(n)}.$$
\edfn

\rm
Степенные суммы и элементарные симметрические многочлены являются частным случаем мономиальных.
\erm

\end{comment}



Рассмотрим один пример, где симметрические функции появляются в качестве промежуточного технического средства.

\dfn Элемент $\alpha \in \mb C$ называется целым алгебраическим или просто целым, если существует такой многочлен $f(x)\in \mb Z[x]$, что $f(\alpha)=0$ и при этом $f\neq 0$ и старший коэффициент $f$ равен 1.
\edfn

Всю эту технику можно применить к решению систем уравнений, в которые переменные входят в симметрично. Например, если у вас есть система

$$\begin{cases}
x + y + z = a\\
xy + yz + zx = b\\
xyz = c,\\
\end{cases}$$
то элементы $x,y,z$ являются корнями $x^3-ax^2+bx-c$. В частности, система
$$\begin{cases}
x + y + z = 6\\
xy + yz + zx = 11\\
xyz = 6,\\
\end{cases}$$
имеет корнями всевозможные перестановки $(1,2,3)$.

\section*{Дополнительно: оценка на коэффициенты делителя}

Сначала мы поборемся с первым осложнением. Заведём  на пространстве многочленов скалярное произведение $$\lan f(x), g(x)\ran = \sum a_ib_i,$$ где $a_i$ и $b_i$ -- коэффициенты $f$ и $g$. Теперь докажем лемму:

\lm Пусть $f\in \mb C[x]$ имеет вид $f=(x-\alpha)h$. Тогда $|f|=|(\alpha x-1)h|$.
\elm

Сформулируем теорему:

\thrm
Пусть $f=a_0 + a_1x+\dots + a_n x^n \in \mb Z[x]$. Тогда для коэффициентов целочисленного делителя $f$ степени $m$ имеет место оценка
$$|b_j| \leq C_{m-1}^j |f| + C_{m-1}^{j-1}|a_n|.$$
\proof Пусть $g(x)$ -- некоторый многочлен. Имеем разложение $g(x)=b_m \prod_{i=1}^m (x-\alpha_i)$. Тогда рассмотрим многочлен 
$$h(x)=\prod_{|\alpha_i|\geq 1} (x-\alpha_i) \prod_{|\alpha_i|<1}(\alpha_ix-1).$$
Мы знаем по предыдущей лемме, что $|g|=|h|$. Определим величины
$$M(g)=\prod_{|\alpha_i|\geq 1} |\alpha_i|, \,\,\, m(g)=\prod_{|\alpha_i|<1}|\alpha_i|.$$
Тогда имеет место
$$|g|^2=|h|^2\geq |b_m|^2 (M(g)^2+m(g)^2).$$
Для этого заметим, что старший коэффициент $h$ по модулю есть $|b_n|m(g)$, а младший -- $|b_n|M(g)$, что и даёт неравенство. В частности применяя это к многочлену $f$ получаем, что $$M(g) \leq \frac{|A|}{a_m},$$
То есть мы оценили некоторое выражение от корней многочлена $f$. Вернёмся пока к многочлену произвольному многочлену $g$. Имеем следующую оценку на его коэффициент:
$$|b_j| = |b_m| \left|\sum \alpha_{i_1}\dots \alpha_{i_{m-j}}\right| \leq |b_m| \left|\sum \beta_{i_1}\dots \beta_{i_{m-j}}\right|, $$
где $\beta=\max(1,|\alpha|)$.

Покажем лемму

\lm Пусть есть набор вещественных чисел $x_1,\dots,x_m\geq 1$, что $x_1\dots x_m=M$. Тогда для всех $0<j\leq n$ имеем $$\sigma_j(x_1,\dots,x_m) \leq C_{m-1}^j M+ C_{m-1}^{j-1}.$$
\proof Покажем, что максимум модуля $\sigma_j$ достигается, если $x_1=\dots=x_{m-1}=1$ и $x_m=M$. Рассмотрим, например, пару $x_1,x_2$. Если $x_1,x_2\neq 1$, то заменим её на пару $1,x_1x_2$. Покажем, что при этом значение $\sigma_j$ увеличилось. Действительно, в новой сумме изменились только слагаемые в которые входили только $x_1$ или только $x_2$. Выпишем их 
$$\sum_{2<i_2 \dots< i_j} x_1 x_{i_2}\dots x_{i_j}  + \sum_{2<i_2\dots} x_2 x_{i_2}\dots x_{i_j}= (x_1+x_2)\sigma_{j-2}(x_3,\dots,x_m)$$
и сделаем в них замену $x_1=1$ и $x_2=x_1x_2$. Получим
$$(1+x_1x_2)\sigma_{j-2}(x_3,\dots,x_m).$$
Осталось заметить, что $0< x_1x_2 -x_1 -x_2 + 1= (x_1-1)(x_2-1)$ в наших предположениях. Аналогично для других пар переменных.
Теперь 
$$\sigma_j(1,\dots,1,M)= C_{m-1}^{j-1}M + C_{m-1}^j.$$
\endproof
\elm

\noindent Заметим теперь, что произведение $\beta_i = M(g)$. Тогда по лемме
$$|b_j|\leq |b_m| (C_{m-1}^{m-j-1}M(g) + C_{m-1}^{m-j})=|b_m| (C_{m-1}^{j}M(g) + C_{m-1}^{j-1}).$$
Теперь пусть $f \di g $ в $\mb Z[x]$. Тогда $a_n \di b_m$ и $M(g)\leq M(f)$ так как корни $g$ являются корнями $f$. Отсюда
$$|b_j|\leq |b_m| (C_{m-1}^{j}M(g) + C_{m-1}^{j-1})\leq |a_n|(C_{m-1}^{j}M(f) + C_{m-1}^{j-1})\leq C_{m-1}^{j}|f| + C_{m-1}^{j-1}|a_n|.$$

\endproof
\ethrm



Это теорема показывает, что размер записи коэффициентов делителя полиномиально зависит от размера записи многочлена $f$.




\section{Дискриминант и результант}


Всякий многочлен раскладывается на линейные множители в некотором расширении полей. В этом же расширении, если выбрать нумерацию корней, имеет смысл говорить о полиномиальных выражениях от корней этого многочлена. Например $(x_1-x_2)x_3$. В некоторых ситуациях эти выражения могут принимать значения в базовом поле $K$. Однако, априори, взяв разные поля и разные нумерации корней мы можем получить разные числа. Теория симметрических многочленов гарантирует вам, что если исходный полином был симметричен относительно корней, то значение выражения определено вне зависимости от выбора расширения (и, конечно, нумерации). В связи с этим, интересно посмотреть на некоторые выражения, которые характеризуют некоторые свойства многочлена и, будучи симметричными, корректно определены и лежат в базовом поле $K$, что позволяет не возиться с расширениями полей для их вычисления.

Попробуем решить следующую задачу: как определить по коэффициентам многочлена, что они имеют общий множитель? Если имеет место нетривиальное разложение $f=hk_1$, $g=hk_2$, то степень $k_1$ меньше $\deg f=n$, а степень $k_2\leq \deg g=m$. Заметим, что тогда $fk_2-gk_1=0$. Обратно, если найдены такие $k_1$ и $k_2$, то у $f$ и $g$ есть общий множитель. Рассмотрим отображение $K[x]_{\leq m-1}\times K[x]_{\leq n-1} \to K[x]_{\leq n+m-1}$, заданное по правилу
$$(a(x),b(x)) \to a(x)f(x)+b(x)g(x).$$ 
Когда это отображение вырождено? Тогда и только тогда, когда есть многочлены маленьких степеней, что $a(x)f(x)=-b(x)g(x)$. Это происходит тогда и только тогда, когда у многочленов $f$ и $g$ есть общий множитель. С другой это происходит, если определитель этого отображения зануляется в стандартных базисах. Транспонирую эту матрицу и переставляя строки получаем:

\dfn Пусть многочлен $f(x)=a_0+\dots+a_nx^n$, а $g(x)=b_0+\dots+b_mx^m$. Тогда результантом многочленов $f$ и $g$ называется $$Res(f,g)=  \det 
\begin{pmatrix}
a_n & a_{n-1} & \cdots & a_0 & 0 & \cdots & 0 \\
0 & a_n & a_{n-1} & \cdots & a_0 & \cdots & 0 \\
\\
0 & \cdots &  a_n & a_{n-1} & a_{n-2} & \cdots &  a_0 \\
b_m & \cdots & b_1 & b_0 & 0 & \cdots & 0 \\
 \\
0 & \cdots & 0 & b_m & \cdots & b_1 & b_0 
\end{pmatrix}.$$
Эта матрица называется матрицей Сильвестра. 
\edfn

Как мы уже заметили, обнуление результанта для многочленов степени $n$ и $m$ равносильно тому, что они имеют общий множитель. Однако, есть ещё выражение, которое обнуляется в той же ситуации $\prod_{i,j} (x_i-y_j)$, где $x_i$ и $y_j$ -- корни многочленов. Оказывается оба эти выражения практически совпадают. Точнее:

\thrm Пусть многочлен $f(x)=a_0+\dots+a_nx^n$, а $g(x)=b_0+\dots+b_mx^m$ из кольца $K[x]$, где $K$ -- поле. Пусть так же в поле $K$ имеются разложения $f(x)=a_n\prod(x-x_i)$, а $g(x)=\prod (x-y_j)$. Тогда
$$Res(f,g)=a_n^mb_m^n \prod_{i,j} (x_i-y_j),$$
\ethrm
\proof  Докажем, что $Res(f,g)=a_n^mb_m^n \prod_{i,j} (x_i-y_j)$, как многочлены от $x_i, y_j$ используя то, что $Res(f,g)$ зануляется тогда и только тогда, когда у $f,g$ есть общий корень.

Поделим $p(x_1\dots,x_n,y_1,\dots,y_m)=\det S$ на $(x_i-y_j)$ c остатком как многочлен от $x_i$
$$p=(x_i-y_j)q+r(x_1,\dots, x_{i-1},x_{i+1},\dots,x_n,y_1,\dots,y_m).$$
В остатке стоит многочлен $r$ степени 0 по $x_i$, то есть от $x_i$ не зависящий. Подставляя справа и слева $x_i=y_j$ получаем, что $r=0$, то есть $\det S \di (x_i-y_j)$. Тогда $\det S \di \prod (x_i-y_j)$. Осталось сравнить степени и старшие коэффициенты. Для этого покажем лемму

\lm  $$a_n^mb_m^n \prod_{i,j} (x_i-y_j)=(-1)^{mn}b_m^n \prod f(y_j)=a_n^m \prod g(x_i).$$ 
\elm

Теперь видно, что результант есть однородный многочлен степени $m$ по координатам $a_i$ и степени $n$ по координатам $b_j$. Но резьтант обладает в точности тем же свойством. Значит они равны с точностью до обратимого множителя. Для этого найдём коэффициент при $a_n^m$ у обоих выражений. В результанте этот коэффициент идёт с множителем $b_0^m$. В выражении  $(-1)^{mn}b_m^n \prod f(y_j)$ это $(-1)^{mn}b_m^n \prod_{j=1}^m y_j^n$. Оба эти выражения совпадают.

\endproof



Результант двух многочленов может быть определён над любым кольцом. Посмотрим, что из этого можно вытащить. Что значит равенство нулю результанта по $y$ для двух многочленов $f(x,y) $ и $g(x,y)$ из $K[x,y]$? Их результант это многочлен $h(x)$. Рассмотрим точку $x_0$. Допустим, что старшие коэффициенты $f$ и $g$ не обращаются в 0 в точке $x_0$. Тогда равенство нулю результанта $h(x_0)$ -- это равенство нулю результанта многочленов $f(x_0,y)$ и $g(x_0,y)$, что означает, что у последних есть общий корень $y_0$. То есть у системы $f=g=0$ есть корень $(x_0,y_0)$. Таким образом корни результанта -- это  просто $x$-координаты решений системы, или точки, в которых старший коэффициент многочленов обращается в 0.


А что можно вывести из того факта, что у $Res(f,g)=n$ для двух многочленов из $\mb Z[x]$? Разложим $n$ на простые множители. Получим $n=p_1^{\alpha_1} \dots p_k^{\alpha_k}$. Допустим, что $p_i$ не делит старшие коэффициенты $f$ и $g$. Тогда $0=Res(f,g) \mod p_i $ есть $Res(\ovl{f}, \ovl{g})$ и следовательно по модулю $p_i$ у многочленов есть общий корень. Обратно, если у $f$ и $g$ есть общий корень по модулю $p_i$, то $Res(f,g)\di p_i$.

Одно из важных свойств результанта состоит в том, что его можно просто посчитать. Во многом благодаря следующему утверждению:

\bupr Кроме того, если $f=gq+r$, где $\deg r=k$, то 
 $$Res(f,g)=(-1)^{(n-k)m}b_m^{n-k} Res(r,g).$$
\eupr

\dfn Дискриминантом многочлена $f=a_0+\dots +a_nx^n$ называется выражение 
$$D(f)=a_n^{2n-2}\prod_{i\neq j} (x_i-x_j)^2.$$
\edfn

\lm Имеет место равенство $Res(f,f')=(-1)^{\frac{n(n-1)}{2}} a_n D(f).$
\elm

\exm\\
1) $D(x^2+ax+b)=-4b+a^2$.\\
2) $D(x^3+ax+b)=-27b^2-4a^3$.\\


Дискриминант даёт ответ на вопрос, когда многочлен не имеет кратных корней по модулю $p$. Действительно это происходит только тогда, когда $D(f)\ndi p$. Заметим, что это условие может нарушаться только в конечном числе $p$, если $D(f)\neq 0$. Таким образом либо у многочлена есть кратный корень, либо у него нет кратных корней для почти всех $p$. Это обосновывает, что для применения леммы Гензеля для подъёма всегда можно выбрать подходящее простое, если многочлен $f$ был бесквадратный.



\chapter{Конечные поля}
Основным героем этой части будут конечные поля. На текущий момент рассмотрение конечных полей было мотивировано тем, что нам необходимо раскладывать многочлены над $\mb Z/p$ на множители. Мы постараемся с этим справится и получить ещё несколько приложений даже во внеалгебраическом круге задач.


\section{Общие факты теории полей}
\dfn[Степень расширения] Пусть $L$ расширение поля $K$. Тогда $\dim_K L$ называется степенью $L$ над $K$ и обозначается как $[L: K]$. Если $[L: K]$ конечно, то говорят, что $L$ -- конечное расширение поля $K$. 
\edfn

\thrm[О башне полей] Пусть дана башня расширений $K\leq L \leq M$. Тогда 
$$[M: K]=[M: L][L: K].$$
В частности, если $M$ конечно над $L$, а $L$ конечно над $K$, то $M$ конечно над $K$.
\ethrm

\crl Пусть $[L: K]$ -- конечное расширение степени $n$, а $[M:K]$ -- степени $d$. Тогда, если $d \ndi n$, то $M$ не может быть подрасширением $L/K$.
\ecrl

\dfn Пусть $L/K$ расширение полей, а $\alpha \in L$. Тогда наименьшее подрасширение $L$ содержащее $\alpha$ будем обозначать $K(\alpha)$, а наименьшую подалгебру будем обозначать $K[\alpha]$. Если есть несколько элементов $\alpha_1,\dots,\alpha_n\in L$, то аналогичные объекты будем обозначать как $K[\alpha_1,\dots,\alpha_n]$ и $K(\alpha_1,\dots,\alpha_n)$.
\edfn

\dfn Элемент $\alpha \in L$ называется алгебраическим над $K$, если существует многочлен $0\neq p(x)\in K[x]$, что $p(\alpha)=0$. 
\edfn

Может показаться, что такое обозначение не естественно, потому что никак не включает в себя объемлющее поле $L$. Я покажу, что это не так страшно.


\thrm Пусть $L/K$ расширение полей, а $\alpha \in L$. Тогда если $\alpha$ алгебраическое над $K$, то $$K(\alpha)=K[\alpha]\cong K[x]/p(x),  \text{ где $p(x)$ минимальный многочлен для $\alpha$}.$$
Если же $\alpha$ не алгебраическое, то $$K[\alpha]\cong K[x], K(\alpha) \cong K(x).$$
\ethrm
\proof Итак, пусть $\alpha$ -- алгебраический над $\mb K$. Тогда минимальный многочлен $\alpha$ однозначно определён. Покажем, что он неприводим. Пусть $p(x)=h(x)q(x)$. Тогда $h(\alpha)q(\alpha)=0$. Но $L$ -- поле. Откуда либо $h(\alpha)=0$ либо $q(\alpha)=0$. Но тогда $p(x)$ не минимальный.

Теперь покажем следующее -- существует единственный гомоморфизм $\ffi \colon K[x]/p(x) \to L$ переводящий $x \to \alpha$. Действительно, есть гомоморфизм $K[x]\to L$, переводящий $x\to \alpha$, $p(x)$ лежит в его ядре. Это даёт гомоморфизм $K[x]/p(x) \to L$. 
Понятно, что такой гомоморфизм может быть только единственным.

Заметим, что его образ это поле и состоит из линейных комбинаций $1,\alpha,\dots,\alpha^{n-1}$, где $n$ -- степень $p(x)$. Понятно, что любая подалгебра , содержащая $\alpha$ содержит такие элементы. Отсюда $$K[x]/p(x) \cong \im \ffi = K[\alpha]=K(\alpha).$$
Пусть $\alpha$ не алгебраический, то есть трансцендентный. Тогда отображение $K[x] \to L$ переводящее $x\to\alpha$ инъективно. Ясно, что его образ это $K[\alpha]$. Далее заметим, что это отображение продолжается до отображения $K(x) \to L$, потому что образы всех элементов $K[x]$, кроме 0 в $L$ обратимы. Ясно, что образ этого отображения есть подполе и изоморфен $K(x)$. Понятно, что это и есть $K(\alpha)$.   
\endproof

\crl Пусть $\alpha$ -- алгебраическое. Тогда $\deg K[\alpha]= \deg K[x]/p(x)= \deg p(x)$, где $p(x)$ -- минимальный многочлен $\alpha$.
\ecrl

\crl Все расширения, порождённые над $K$ корнем одного и того же неприводимого многочлена изоморфны. Часто я буду говорить, про расширение $K[\alpha]$, где $\alpha$ корень многочлена $p(x)$. Это корректно, так как такое расширение определено однозначно с точностью до изоморфизма.
\ecrl

Попробуем применить это следствие для доказательства невозможности определённых  построений, например при помощи циркуля и линейки. Напомню, что при построении циркулем и линейкой можно поставить пару начальных точек (задать масштаб), соединять две построенные  точки прямой и строить окружность с центром в построенной точке и с расстоянием, равным расстоянию между уже построенными двумя точками. Точка построена, если она есть точка пересечения построенных прямых и окружностей. 

Вещественное число $x$ называется построимым, если стартуя с точек $(0,0)$ и $(1,0)$ можно построить отрезок $(x,0)$. 

\thrm Если вещественное число $x$ построимо, то оно алгебраическое и лежит в расширении $L/\mb Q$ степени $2^m$.
\proof Доказательство идёт индукцией по числу построений. Пусть уже построены прямые $l_i$ и окружности $O_j$. Заметим, что коэффициенты в уравнениях $O_i$ и $l_j$ по индукционному предположению лежат в подполе $L\subseteq \mb R$ степени $2^m$ над $\mb Q$. Тоже касается и новой прямой $l$ (или окружности $O$). Посмотрим на пересечение окружности $O_j$ и новой $l$. Она заданы уравнениями $(x-a)^2+(y-b)^2=r^2$ и $cx+dy=f$. Пусть $c\neq 0$. Тогда первое уравнение переписывается в виде $$(f-dy)^2+c^2(y-b)^2=c^2r^2$$
Его коэффициенты из $L$, а решение $y$ лежит либо в $L$ либо в расширении степени 2 над $L$. Случай пересечения двух окружностей сводится к пересечению окружности и прямой.  
\endproof
\ethrm

\crl
Нельзя разбить произвольный угол на три части при помощи циркуля и линейки.
\proof Например, угол $\frac{\pi}{9}$ нельзя. Действительно, построимость угла и его косинуса равносильны. Косинус $\frac{\pi}{9}$ удовлетворяет уравнению $4x^3-3x=\frac{1}{2}$. Это неприводимый над $\mb Q$ многочлен степени 3 и его корни не могут лежать в расширении степени $2^m$. Следовательно, построение невозможно. 
\endproof
\ecrl

\begin{comment}

\dfn Пусть $K$ -- поле, $f(x)\in K[x]$. Тогда поле $L$ называется полем разложения $f$, если над $L$ многочлен $f$  раскладывается на линейные множители $f(x)=\prod (x-\alpha_i)$ и $L=K[\alpha_1,\dots,\alpha_n]$.
\edfn



\thrm Поле разложения многочлена существует и единственно.
\ethrm
\proof Прежде всего заметим, что мы уже знаем алгоритм построения поля разложения. Действительно. Для этого разложим $f$ на неприводимые множители $f=f_1\dots f_k$ и рассмотрим $L_1=K[\alpha_1]$, где $\alpha_1$ корень $f_1$. Над $L_1$  рассмотрим $f(x)/(x-\alpha_1)$ и построим его поле разложения над $L_1$, которое есть по индукционному предположению. Это и будет искомое $L$. Действительно, многочлен $f$ точно раскладывается над $L$ на линейные множители.  Далее, $L=L_1[\alpha_2,\dots,\alpha_n]$, то есть любой элемент этого поля есть многочлен от $\alpha_i$ с коэффициентами из $L_1$, которые есть многочлены от $\alpha_1$. Осталось раскрыть скобки.
\endproof

\end{comment}

\section{Строение конечных полей}

\lm Пусть $K$ --- поле, $p=\chr K$ --- простое число. Тогда в $K$ есть подполе изоморфное $\mb Z/p$. Если к тому же $K$ --- конечное, то число элементов $|K|=p^n$ для некоторого натурального $n$. 
\elm
\proof Рассмотрим гомоморфизм $f\colon \mb Z \to K$. Ядро этого отображения это $p\mb Z$. Тогда $\im f\cong \mb Z/p$. Пусть теперь $K$ конечно. Рассмотрим $K$ как группу по сложению. Заметим, что порядок любого ненулевого элемента равен $p$. Так как нет элементов другого порядка, то в группе $p^n$ элементов по теореме Коши.
\endproof
Обычно доказательство идёт через линейную алгебру.


\thrm Существует и единственно (с точностью до изоморфизма) поле из $p^n$ элементов. Такое поле будем обозначать $\mb F_{p^n}$.
\ethrm

Начнём с леммы:
\lm Пусть $K$ поле из $p^n$ элементов. Тогда все элементы $K$ удовлетворяют уравнению $x^{p^n}=x$.
\elm
\proof Группа $K^*$ состоит из $p^n-1$ элементов. Тогда все элементы из $K^*$ удовлетворяют уравнению $x^{p^n-1}-1=0$. Домножая на $x$ добавляем неприкаянный 0.
\endproof


\lm Пусть $L$ --- кольцо характеристики $p$. Тогда отображение $x\to x^{p}$ является эндоморфизмом $L$. Это отображение называется эндоморфизмом Фробениуса. Если $L$ - конечное поле, то эндоморфизм Фробениуса является автоморфизмом. 
\elm
\proof Очевидно произведение переходит в произведение. $(x+y)^p=\sum_{i+j=p}{{p}\choose{i}} x^iy^j= x^p+y^p$ т.к. все промежуточные биномиальные коэффициенты делятся на $p$. Пусть теперь $L$ -- поле. Тогда заметим, что отображение $\Frob$ инъективно, так как в поле не бывает нильпотентов и, следовательно, по принципу Дирихле, биективно.
\endproof

\lm Пусть $L$ --- поле характеристики $p$. Тогда множество элементов из $L$ удовлетворяющих уравнению $x^{p^n}=x$ образует подполе в $L$.
\elm
\proof Обозначим рассматриваемое множество за $K$. Тогда $0,1\in K$. Очевидно, что $K$ замкнуто относительно умножения. Замкнутость относительно сложения следует из того, что $x^{p^n}$ есть композиция $n$ раз эндоморфизма Фробениуса. Значит $K$ --- подкольцо. Обратный к $x\neq 0$ имеет вид $x^{p^n-2}$, что следует из уравнения.
\endproof


\proof[{\color{red!80!black} Доказательство теоремы. Существование}]
Рассмотрим поле $\mb F_p=\mb Z/p$ и $x^{p^n}-x$ --- многочлен над ним. Тогда есть поле $L$ в котором   $x^{p^n}-x$ раскладывается на линейные множители. Рассмотрим $K$ --- подполе в $L$ состоящее из элементов удовлетворяющих уравнению $x^{p^n}=x$. В $K$ ровно $p^n$ элементов т.к. многочлен $x^{p^n}-x$ не имеет кратных корней.

\proof[Доказательство теоремы. Единственность]
Пусть есть два поля $K$ и $L$ из $p^n$ элементов. Рассмотрим их мультипликативные группы. Они циклические порядка $p^n-1$. Пусть группа $K^*$ порождена элементом $\xi$. Тогда любой элемент заведомо является многочленом от $\xi$. Пусть $f$ -- минимальный многочлен $\xi$. Значит $K\cong\mb F_p[x]/f(x)$. Многочлен $f$ неприводим. $\xi$ --- его корень. Многочлен $x^{p^n}-x$ делится на $f$, так как у них есть общий корень $\xi$. Тогда у $f$ есть корни в любом поле из $p^n$ элементов, в частности в $L$. Тогда у нас есть гомоморфизм  $K\cong\mb F_p[x]/f(x)\to L$ переводящий $\xi$ в какой-то корень $f$. Этот гомоморфизм инъективен и по принципу Дирихле является биекцией. 
\endproof

\rm В частности, мы увидели, что любое конечное поле $\mb F_{p^n}$ имеет вид $K\cong\mb F_p[x]/f(x)$. Степень $f$ равна $n$ исходя их подсчёта числа элементов.
\erm


\thrm Поле $\mb F_{p^n}$ подполе $\mb F_{p^m}$ тогда и только тогда, когда $m\di n$. Такое подполе единственно.
\ethrm 
\proof
Если $\mb F_{p^n}$ подполе $\mb F_{p^m}$, то сравнивая степени расширения получаем, что $m \di n$. Обратно, возьмём в $\mb F_{p^m}$ подполе $\{x \in \mb F_{p^m} \,|\, x^{p^n}-x=0\}$. Очевидно, что любое подполе из $p^n$ элементов там содержится. Это даёт единственность. Для того, чтобы доказать существование покажем, что в указанном подполе $p^m$ элементов. Для этого заметим, что многочлен $x^{p^m}-x \di x^{p^n}-x$, если $m \di n$. Первый многочлен раскладывается на линейные множители над $\mb F_p$, откуда аналогичное свойство выполнено для второго многочлена. То есть у многочлена $x^{p^n}-x$ есть все $p^n$ корней в $\mb F_{p^m}$. Что и требовалось. 
\endproof



Покажем, что аналогичные свойства верны для расширений поля $\mb F_q$, где $q=p^n$. Большая их часть, естественно, сводится к расширениям $\mb F_p$, однако, в некоторых вопросах возникают дополнительные сложности. Основная из них -- наличие нетривиальных автоморфизмов у таких полей над $\mb F_p$. Начнём с леммы.

\lm Все автоморфизмы $\mb F_q$ над $\mb F_p$ имеют вид $\Frob_p^{\circ i}$, где $0\leq i \leq n-1$. 
\proof Заметим, что поле $\mb F_q$ порождено одним элементом $\mb F_q =\mb F_p[\alpha]$. Минимальный многочлен $\alpha$ над $\mb F_p$ обозначим за $f$, его степень равна $n$. 

Теперь, гомоморфизмы $\mb F_p[\alpha]$ определяются образами элемента $\alpha$, которые обязаны быть корнями того же многочлена $f$. Но таких корней в $\mb F_p[\alpha]$ не более $n$. Тогда и автоморфизмов не более $n$! Осталось показать, что мы нашли все $n$ возможных. Для этого предположим, что для всех элементов из $\mb F_q$ выполнено, что $\Frob_p^{\circ l} - \Frob_p^{\circ k}=0$, для $k,l<n$. Но это уравнение степени меньше $p^n$. Ему не могут удовлетворять все элементы $\mb F_q$!. 
\endproof
\elm

\thrm Все расширения поля $\mb F_q$, где $q=p^n$ имеют $q^m$ элементов. Два расширения $\mb F_q$ из $q^m$ элементов изоморфны между собой. Внутри поля $\mb F_{q^m}$ есть подполе $\mb F_{q^l}$ только если $l|m$.
\proof
Если $L$ расширение $\mb F_q$, то оно имеет $q^{[L:\mb F_q]}$ элементов. Покажем существование. Возьмём поле из $q^m=p^{nm}$ элементов и рассмотрим в нём подполе $\mb F_q$ из $q=p^n$ элементов. Такое есть по предыдущей теореме. Это и даёт необходимое расширение. 

Покажем единственность такого расширения с точностью до $\mb F_q$ изоморфизма. Основная сложность состоит в том, чтобы проследить за сохранением $\mb F_q$ коэффициентов. Итак, пусть $L_1$ и $L_2$ -- расширения $\mb F_q$ из $q^m$ элементов. Такие поля изоморфны над $\mb F_p$. Пусть $\ffi \colon L_1 \to L_2$ изоморфизм над $\mb F_p$. Вообще говоря он не обязан переводить элементы из $\mb F_q$ в себя же. Нам надо подправить его, чтобы он так делал. Для этого заметим, что $\ffi(\mb F_q)=\mb F_q$. Таким образом у нас возникает автоморфизм $\mb F_q \to \mb F_q$. Он имеет вид $\Frob^{\circ i}$. Тогда на всём поле $L_2$ рассмотрим автоморфизм $\ffi'=\Frob^{\circ -i}$. Тогда композиция $\ffi'\circ \ffi$ и есть подходящий изоморфизм.

Теперь рассмотрим поле из $q^m$ элементов. Тогда в нём есть подполе из $q^l$ элементов только если $nm \di nl$. Но это происходит только если $m \di l$. Такое подполе единственно и автоматически снабжается структурой $\mb F_q$ расширения, так как содержит образ последнего при его вложении в $\mb F_{q^m}$.
\endproof
\ethrm

Покажем одну полезную теорему про многочлены над конечным полем.

\thrm Пусть $f(x)$ -- это неприводимый многочлен из $\mb F_q[x]$. Тогда $x^{q^m}-x \di f(x)$ тогда и только тогда, когда $\deg f(x) | m$.
\proof Пусть $x^{q^m}-x$ делится на $f(x)$. Тогда в поле $\mb F_q^m$ многочлен $f(x)$ имеет корень $\alpha$ (на самом деле там лежат все его корни). Теперь $\mb F_q[\alpha]$ подполе $\mb F_{q^m}$. Но тогда $\deg f(x) = [\mb F_q[\alpha]: \mb F_q] \di m $. 

Обратно, пусть $k=\deg f(x) | m$. Тогда в $\mb F_q^m$ есть подполе $\mb F_{q^k}$. Но такое подполе изоморфно $\mb F_q[x]/f$ и имеет внутри корень $\alpha$ многочлена $f(x)$. Но тогда $f(x)$ и $x^{q^m}-x$ не взаимно просты, откуда следует, что $x^{q^m}-x \di f(x)$, благодаря неприводимости последнего. 
\endproof
\ethrm



\section{Алгоритм Берлекемпа}


Опишем здесь некоторый набор соображений и алгоритмов касательно разложения многочленов на множители над конечным полем. 

Мы помним, что над полями характеристики 0 всегда легко выделить все  кратные множители многочлена просто взяв отношение $f$ и $\Nod(f,f')$. Однако, над конечными полями всё немного не так. Точнее

\lm Пусть $f= \prod g_i^{n_i}$. Тогда $$\Nod(f,f')=\prod_{n_i \ndi p}g_i^{n_i-1} \prod_{n_i \di p}g_i^{n_i}.$$
\proof
Рассмотрим неприводимый множитель $g_i$. Пусть $f(x)=g_i(x)^{n_i}g(x)$. Продифференцируем. Имеем $f'(x)= n_ig_i'(x)g_i^{n_i-1}+ g_i^{n_i}g'(x)$. Если $n_i\ndi p$, то кратность вхождения $g_i(x)$ в $f'(x)$ равна $n_i-1$. Если же $n_i\di p$, то $f'(x)=g_i^{n_i}g'(x)$, что показывает, что степень вхождения $g_i$ в $\Nod(f,f')$ не менее $n_i$. Но в $f(x)$ многочлен  
\elm

\lm Многочлен $h$ над конечным полем характеристики $p$ имеет нулевую производную тогда и только тогда, когда он является $p$-ой степенью. Извлечение степени можно провести эффективно.
\proof Как мы уже знаем с прошлого семестра, если $h'=0$, то $h=g(x^p)$. Посмотрим на коэффициенты $g$ -- $a_0, \dots, a_l\in \mb F_q$. Вспомним, что эндоморфизм Фробениуса $\Frob \colon \mb F_q \to  \mb F_q $ -- биекция. Иными словами из каждого элемента можно извлечь корень степени $p$. Пусть $b_i^p=a_i$. Тогда $f=b_0+b_1x+\dots+b_lx^l$ обладает свойством $f^p=g(x^p)=h$. Как вычислить корень степени $p$ из элемента? Для этого заметим, что обратное отображение к $\Frob \colon \mb F_q \to \mb F_q$ это $\Frob^{\circ n-1}$. 
\endproof
\elm 


Это позволяет свести задачу к разложению на множители многочлена без кратных множителей. Действительно $\frac{f}{\Nod(f,f')}$ без кратных множителей. В свою очередь $\Nod(f,f')$ состоит из множителей двух типов -- чьи степени кратны $p$ и не кратны $p$. Первые встречаются как сомножители в  $\frac{f}{\Nod(f,f')}$ и легко находятся после получения его разложения. Из оставшихся множителей можно извлечь корень степени $p$ и перейти к разложению многочлена заведомо меньшей степени. 

Другое соображение позволяет свести задачу к разложению многочленов, чьи неприводимые сомножители имеют одинаковую степень. 

Заметим, что неприводимый многочлен степени $k$, является делителем $x^{q^k}-x$, но не являются делителями $x^{q^l}-x$ ни для каких $l<k$. Пусть $f$ -- многочлен степени ровно $n$ над $\mb F_q$. Без ограничения общности будем считать, что многочлен $f$ без квадратов.

\thrm  Существует полиномиальная от размера $f$ (то есть от $n\log q$) процедура, которая разделяет $f$ на сомножители $f_1, \dots, f_k$, что $f_i$ состоит из неприводимых сомножителей степени ровно $i$.
\proof  Переберём все многочлены вида $g_l=x^{q^l}-x$, где $l<n$. Пусть на шаге $l$ у многочлена $f$ нет неприводимых множителей степени меньше $l$. Тогда $\Nod(g_l,f)$ состоит из всех множителей степени ровно $l$ (они ведь входят в $f$ с кратностью 1). Тогда $\frac{f}{\Nod{g_l,f}}$ состоит из неприводимых множителей степени больше $l$ 

Осталось пояснить, как посчитать $\Nod(f,g_l)$. Проблема в том, что размер $g_l$ не полиномиально зависит от размера $f$. Здесь на помощь приходит следующее соображение: пусть $r$ -- остаток от деления $g_l$ на $f$. Тогда $\Nod(g_l,f)=\Nod(r,f)$. Степень же $r$ меньше  степени $f$. Осталось понять, как быстро найти $r$. Для этого надо вычислить $x^{q^l} \mod f$. Но для этого надо всего лишь возвести $x$ в степень $q^l$ в кольце $\mb F_q[x]/f$, что делается за $l\log q$ операций умножения в этом кольце, то есть за $l\log q$ умножений многочленов степени меньше $n$ и вычислений остатков для многочленов степени не более $2n$.
\endproof 
\ethrm  



\thrm[Алгоритмы Берлекэмпа] Пусть $f(x)\in \mb F_q$ без кратных множителей. Тогда существуют детерминированный полиномиальный по $n$ (но не по $\log q$)  алгоритм раскладывающий $f$ на множители. 
\proof Первое соображение, которое мы применим, будет состоять в том, что мы переформулируем  задачу факторизации многочлена $f$ как задачу про некоторое кольцо. Точнее, пусть $f=h_1\dots h_l$ разложение на неприводимые. Тогда по Китайской теореме об остатках 
$$R=F_q[x]/f\cong F_q[x]/h_1 \times \dots \times K[x]/h_l.$$ 
Заметим, что нахождение нетривиального делителя нуля в $R$ равносильно нахождению делителя $f$. Заметим, что, в свою очередь, $F_q[x]/h_i$ -- поле из $q^{\deg h_i}$ элементов. Делителем нуля является любой элемент с хотя бы одним нулём в компоненте.


В каждом таком поле есть единственное подполе из $q$ элементов, состоящее из решений уравнения $x^q-x=0$. Если рассмотреть множество решений этого уравнения в $R$, то оно будет состоять из $l$-ек покомпонентных решений. Иными словами множество решений уравнения $x^q-x$ в $\mb R$ есть подалгебра $R'$, изоморфная $F_q\times \dots \times F_q$, взятое $l$ раз. Если мы найдём делитель нуля в этой подалгебре, то найдём и в исходной. Заметим, что удельно, делителей нуля в этой подалгебре больше чем в исходной. 

Как найти $R'$? Для этого надо найти все решения уравнения $x^q-x=0$ в $R$. Второе соображение состоит в том, что это уравнение линейно (над $\mb F_q$). Чтобы решить это линейное уравнение надо составить его матрицу. У отображения $x \to -x$ матрица $-E_n$, где $n=\deg f$. У оператора $x \to x^q$ матрица легко считается. Далее достаточно применить любой из методов для решения систем линейных уравнений. Заметим, что если алгебра $R'$ одномерна (она не менее чем одномерна, так как константа всегда решение), то многочлен $f$ неприводим.

Теперь мы нашли $R'$. Построим детерминированный алгоритм нахождения разложения. Напомню, что нам надо получить делитель нуля, то есть элемент, у которого хоть одна компонента не 0. Возьмём произвольный не константный элемент $h$ из $R'$.  Тогда $h$ соответствует $l$-ка $(a_1,\dots,a_{l})$.  Переберём все константы $c$ из $K$. Их $q$ штук (это и даёт неполиномиальность алгоритма по $\log q$). Тогда $h-c$ для, например, $c=a_1$ есть нетривиальный делитель 0 (он не ноль, потому что $h$ не константа).

Делитель $f$ теперь можно найти как $\Nod(f,h-c)$.
 
\endproof
\ethrm





\end{document}